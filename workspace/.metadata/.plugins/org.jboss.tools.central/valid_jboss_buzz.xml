<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Kubernetes-native Apache Kafka with Strimzi, Debezium, and Apache Camel (Kafka Summit 2020)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/jUCkpD9-4LI/" /><category term="CI/CD" /><category term="Event-Driven" /><category term="Kubernetes" /><category term="Operator" /><category term="Stream Processing" /><category term="change data capture" /><category term="database integration" /><category term="debezium" /><category term="Kafka connector" /><category term="kafkasummit" /><category term="kubernetes-native" /><author><name>Hugo Guerrero</name></author><id>https://developers.redhat.com/blog/?p=767187</id><updated>2020-08-21T07:00:57Z</updated><published>2020-08-21T07:00:57Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; has become the leading platform for building real-time data pipelines. Today, Kafka is heavily used for developing &lt;a href="https://developers.redhat.com/topics/event-driven/"&gt;event-driven applications&lt;/a&gt;, where it lets services communicate with each other through events. Using &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; for this type of workload requires adding specialized components such as Kubernetes Operators and connectors to bridge the rest of your systems and applications to the Kafka ecosystem.&lt;/p&gt; &lt;p&gt;In this article, we&amp;#8217;ll look at how the open source projects Strimzi, Debezium, and Apache Camel integrate with Kafka to speed up critical areas of Kubernetes-native development.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Red Hat is sponsoring the Kafka Summit 2020 virtual conference from August 24-25, 2020. See the end of this article for details.&lt;/p&gt; &lt;p&gt;&lt;span id="more-767187"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Kafka on Kubernetes with Strimzi&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://strimzi.io/"&gt;Strimzi&lt;/a&gt; is an open source project that is part of the &lt;a target="_blank" rel="nofollow" href="https://www.cncf.io/"&gt;Cloud Native Computing Foundation&lt;/a&gt; (CNCF) that makes it easier to move Apache Kafka workloads to the cloud. Strimzi relies on the abstraction layer provided by Kubernetes and the &lt;a href="https://developers.redhat.com/topics/kubernetes/operators/"&gt;Kubernetes Operator&lt;/a&gt; pattern. Its main focus is running &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Apache Kafka on Kubernetes&lt;/a&gt; while providing &lt;a href="https://developers.redhat.com/topics/containers/"&gt;container&lt;/a&gt; images for Kafka, Zookeeper, and other components that are part of the Strimzi ecosystem.&lt;/p&gt; &lt;p&gt;Strimzi extends the Kubernetes API with Kafka-related custom resource definitions (CRDs). The main Kafka CRD describes a Kafka cluster to deploy, as well as the Zookeeper ensemble that is needed. But Strimzi is not just for the broker; you can also use it to create and configure topics, and create users to access those topics. Strimzi also supports the configuration for mirroring data between clusters using &lt;a target="_blank" rel="nofollow" href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0"&gt;Kafka MirrorMaker 2.0&lt;/a&gt; custom resources, as well as deploying and managing the &lt;a target="_blank" rel="nofollow" href="https://strimzi.io/docs/bridge/latest/"&gt;Strimzi Kafka Bridge&lt;/a&gt; for HTTP clients.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;/b&gt;&lt;a href="https://developers.redhat.com/blog/2020/08/14/introduction-to-strimzi-apache-kafka-on-kubernetes-kubecon-europe-2020/"&gt;Introduction to Strimzi: Apache Kafka on Kubernetes (KubeCon Europe 2020)&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Change data capture with Debezium&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://debezium.io/"&gt;Debezium&lt;/a&gt; is a set of distributed services that captures row-level changes in your databases so that your applications can see and respond to the changes. Debezium records all row-level changes committed to each database table in a transaction log. Applications simply read the transaction logs they&amp;#8217;re interested in and see all of the events in the order in which they occurred. Debezium is durable and fast, so apps can respond quickly and never miss an event, even when things go wrong.&lt;/p&gt; &lt;p&gt;Debezium provides connectors for monitoring the following databases:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;MySQL Connector&lt;/li&gt; &lt;li&gt;PostgreSQL Connector&lt;/li&gt; &lt;li&gt;MongoDB Connector&lt;/li&gt; &lt;li&gt;SQL Server Connector&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Debezium connectors record all events to a &lt;a href="https://developers.redhat.com/blog/2018/10/29/how-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams/"&gt;Red Hat AMQ Streams&lt;/a&gt; Kafka cluster. Applications then consume those events through AMQ Streams. Debezium uses the &lt;a href="https://developers.redhat.com/blog/2020/02/14/using-secrets-in-apache-kafka-connect-configuration/"&gt;Apache Kafka Connect&lt;/a&gt; framework, which makes all of Debezium&amp;#8217;s connectors into Kafka Connector source connectors. As such, they can be deployed and managed using AMQ Streams&amp;#8217; Kafka Connect custom Kubernetes resources.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Learn more&lt;/strong&gt;: &lt;a href="https://developers.redhat.com/blog/2020/04/14/capture-database-changes-with-debezium-apache-kafka-connectors/"&gt;Capture database changes with Debezium Apache Kafka connectors&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Kafka connectivity with Apache Camel Kafka Connect&lt;/h2&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/"&gt;Apache Camel&lt;/a&gt; community has built one of the &lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/blog/ASF-Report-2019/"&gt;busiest open source integration frameworks&lt;/a&gt; in the Apache Foundation ecosystem. Camel lets you quickly and easily integrate data consumer and producer systems. It also implements the most used &lt;a target="_blank" rel="nofollow" href="https://www.enterpriseintegrationpatterns.com/"&gt;enterprise integration patterns&lt;/a&gt; and incorporates popular interfaces and protocols as they emerge.&lt;/p&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/camel-kafka-connector/latest/index.html"&gt;Camel Kafka Connector&lt;/a&gt; subproject focuses on using Camel components as &lt;a href="https://developers.redhat.com/blog/2020/05/19/extending-kafka-connectivity-with-apache-camel-kafka-connectors"&gt;Kafka Connect connectors&lt;/a&gt;. To this end, the development team built a tiny layer between the Camel and Kafka frameworks, which allows you to easily use each Camel component as a Kafka connector in the Kafka ecosystem. More than 340 Camel Kafka connectors support integrations with everything from AWS S3 to Telegram and Slack. All of these connectors are available to use with Kafka without throwing a single line of code.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Learn more&lt;/strong&gt;: &lt;a href="https://developers.redhat.com/blog/2020/05/19/extending-kafka-connectivity-with-apache-camel-kafka-connectors/"&gt;Extending Kafka connectivity with Apache Camel Kafka connectors&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;New organizations are adopting Apache Kafka as an event backbone every day. Communities like Apache Camel are working on how to speed up development in key areas such as integration. The Debezium community provides specialized connectors that simplify integrating database-generated events from microservices or legacy applications into modern, event-driven architectures. Finally, CNCF projects like Strimzi make it easier to access the benefits of Kubernetes and deploy Apache Kafka workloads in a cloud-native way.&lt;/p&gt; &lt;p&gt;For those who want an open source development model with enterprise support, &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/products/integration"&gt;Red Hat Integration&lt;/a&gt; lets you deploy your Kafka-based event-driven architecture on &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, the enterprise Kubernetes. &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/resources/amq-streams-datasheet"&gt;Red Hat AMQ Streams&lt;/a&gt;, Debezium, and the Apache Camel Kafka Connect connectors are all available with a Red Hat Integration subscription.&lt;/p&gt; &lt;h2&gt;Kafka Summit 2020&lt;/h2&gt; &lt;p&gt;If you want to know more about running Apache Kafka on Kubernetes, Red Hat is sponsoring the &lt;a target="_blank" rel="nofollow" href="https://kafka-summit.org/"&gt;Kafka Summit 2020&lt;/a&gt; virtual conference from August 24-25, 2020. You can join either of the following sessions (note that you must be registered to follow these links):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Tuesday, August 25, 2020, at 10:00 a.m. PDT&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://kafkasummit.io/session-virtual/?v26dd132ae80017cdaf764437c30ebe6f10c1b1eeaab01165e44366654b368dfaeab6baf7e386a642ecb238989334530e=29357BABE872174F33FC8355B5D7F6CBA10F9416968BEE4F161E83F2847328787AEE868E65ECEAE3D43713051B9D2B3C"&gt;Change Data Capture Pipelines with Debezium and Kafka Streams&lt;/a&gt; by Debezium project lead Gunnar Morling.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Tuesday, August 25, 2020, at 10:30 a.m. PDT&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://kafkasummit.io/session-virtual/?v26dd132ae80017cdaf764437c30ebe6f10c1b1eeaab01165e44366654b368dfaeab6baf7e386a642ecb238989334530e=21BEFF118082C7BD226CEA8B405E4A27DAC3D4A0A525C2F58BD5774B496BD7899376E76179D6BCF1CA17BC373DD0BE4C"&gt;Camel Kafka Connectors: Tune Kafka to &amp;#8220;Speak&amp;#8221; With (Almost) Everything&lt;/a&gt; by Apache Camel engineers Andrea Cosentino and Andrea Tarocchi.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you want to follow the conversation and talk with the presenters, I&amp;#8217;ll be hosting panel discussions with the engineering leads at these times:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Monday August 24, 2020 from 10:00 a.m. &amp;#8211; 11:00 a.m. PDT&lt;/li&gt; &lt;li&gt;Monday August 24, 2020 from 1:00 p.m. &amp;#8211; 2:00 p.m. PDT&lt;/li&gt; &lt;li&gt;Tuesday August 25, 2020 from 11:00 a.m. &amp;#8211; 12:00 p.m. PDT&lt;/li&gt; &lt;li&gt;Tuesday August 25, 2020 from 1:00 p.m. &amp;#8211; 2:00 p.m. PDT&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Finally, we will have more Red Hatters at the &lt;a target="_blank" rel="nofollow" href="https://kafkasummit.io/virtual-exhibitor/?v0326b739525aaf6a5900c153ea6485e67109462e8db159b156161fc07c7e3d8016769932b4c0398e64b5ea52edb3d1c5=56CC3380CBA86BDA1DB77B0F6C902F3EE409DC5CA6F71077702CE1C9452986BBE14B10CA443311D61A730309F78FE22B"&gt;sponsored booth&lt;/a&gt; throughout the event, to solve your questions regarding running Kafka on Kubernetes.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#038;title=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" data-a2a-url="https://developers.redhat.com/blog/2020/08/21/kubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020/" data-a2a-title="Kubernetes-native Apache Kafka with Strimzi, Debezium, and Apache Camel (Kafka Summit 2020)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/kubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020/"&gt;Kubernetes-native Apache Kafka with Strimzi, Debezium, and Apache Camel (Kafka Summit 2020)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/jUCkpD9-4LI" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Apache Kafka has become the leading platform for building real-time data pipelines. Today, Kafka is heavily used for developing event-driven applications, where it lets services communicate with each other through events. Using Kubernetes for this type of workload requires adding specialized components such as Kubernetes Operators and connectors to bridge the rest of your systems [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/kubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020/"&gt;Kubernetes-native Apache Kafka with Strimzi, Debezium, and Apache Camel (Kafka Summit 2020)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/21/kubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">767187</post-id><dc:creator>Hugo Guerrero</dc:creator><dc:date>2020-08-21T07:00:57Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/21/kubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020/</feedburner:origLink></entry><entry><title>Improved configuration and more in Red Hat CodeReady Workspaces 2.3</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/mAGagwrmXjM/" /><category term="Developer Tools" /><category term="Java" /><category term="Kubernetes" /><category term="Security" /><category term="cluster proxy" /><category term="CodeReady Workspaces" /><category term="jboss" /><category term="Kubernetes secrets" /><category term="openshift" /><author><name>Parag Dave</name></author><id>https://developers.redhat.com/blog/?p=767977</id><updated>2020-08-21T07:00:28Z</updated><published>2020-08-21T07:00:28Z</published><content type="html">&lt;p&gt;Based on &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/che/getting-started/cloud/?sc_cid=701f2000000RtqCAAS"&gt;Eclipse Che&lt;/a&gt;, &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;Red Hat CodeReady Workspaces&lt;/a&gt; (CRW) is a &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;-native developer environment that supports cloud-native development. CodeReady Workspaces 2.3 is now available. For this release, we focused on improving CRW&amp;#8217;s configuration options, updating to the latest versions of IDE plugins, and adding new devfiles.&lt;/p&gt; &lt;p&gt;CodeReady Workspaces 2.3 is available on:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.0/html/installation_guide/installing-codeready-workspaces-on-openshift-3-using-the-operator_crw"&gt;OpenShift 3.11&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.3/html/installation_guide/installing_codeready_workspaces_on_openshift_container_platform"&gt;OpenShift 4.3&lt;/a&gt; and higher, including &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;OpenShift 4.5&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/products/dedicated/"&gt;OpenShift Dedicated&lt;/a&gt; 4.3, via the add-ons capability.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span id="more-767977"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Two ways to inject secrets into workspaces&lt;/h2&gt; &lt;p&gt;Starting with CodeReady Workspaces 2.3, you can automatically mount encrypted &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; secrets that contain sensitive information such as user names, passwords, and authentication tokens into workspace &lt;a href="https://developers.redhat.com/topics/containers/"&gt;containers&lt;/a&gt;. To mount these secrets, you have to create them in OpenShift namespaces, where your workspace containers are created. Let us consider the two mechanisms for mounting secrets to their workspaces: mounting secrets as environment variables, and mounting secrets in a file.&lt;/p&gt; &lt;h3&gt;Mounting secrets as environment variables&lt;/h3&gt; &lt;p&gt;The following YAML file contains two secrets, which are associated with the &lt;code&gt;FIRST_ENV_VAR&lt;/code&gt; and &lt;code&gt;SECOND_ENV_VAR&lt;/code&gt; environment variables. These environment variables are set with the values of &lt;code&gt;myvalue1&lt;/code&gt; and &lt;code&gt;myvalue2&lt;/code&gt;, respectively. Once set, the variables will reside inside of a container named &lt;code&gt;maven&lt;/code&gt; in all of the workspaces that are created in the same OpenShift namespace as this YAML file:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: Secret metadata: name: mvn-settings-secret annotations: che.eclipse.org/target-container: maven che.eclipse.org/mount-as: env che.eclipse.org/firstkey_env-name: FIRST_ENV_VAR che.eclipse.org/secondkey_env-name: SECOND_ENV_VAR labels: … data: firstkey: myvalue1 secondkey: myvalue2 &lt;/pre&gt; &lt;h3&gt;Mounting secrets in a file&lt;/h3&gt; &lt;p&gt;The next sample file shows a secret that is mounted in a file called &lt;code&gt;settings.xml&lt;/code&gt;. The file is available to a container named &lt;code&gt;maven&lt;/code&gt; in all of the workspaces that are created in the same OpenShift namespace as this YAML file:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: Secret metadata: name: mvn-settings-secret labels: app.kubernetes.io/part-of: che.eclipse.org app.kubernetes.io/component: workspace-secret annotations: che.eclipse.org/target-container: maven che.eclipse.org/mount-path: /home/user/.m2/ che.eclipse.org/mount-as: file che.eclipse.org/automount-workspace-secret: true data: settings.xml: __&amp;#60;base64 encoded data content here&amp;#62;__ &lt;/pre&gt; &lt;h2&gt;OpenShift cluster-wide proxy support&lt;/h2&gt; &lt;p&gt;When you enable OpenShift with a cluster-wide egress proxy, CodeReady Workspaces now automatically honors that proxy for communication across its components and external services.&lt;/p&gt; &lt;h2&gt;Experimental workspace storage setting&lt;/h2&gt; &lt;p&gt;You can now set the CheCluster custom resource configuration property &lt;code&gt;CHE_WORKSPACE_STORAGE_AVAILABLE_TYPES&lt;/code&gt; with an experimental value of &lt;code&gt;async&lt;/code&gt;. This value provides a blend of ephemeral and persistent storage. It allows for faster I/O and retains workspace changes.&lt;/p&gt; &lt;h2&gt;Improved reliability for terminal connections&lt;/h2&gt; &lt;p&gt;We improved CodeReady Workspaces to prevent failed task execution due to the disposal of terminal connections.&lt;/p&gt; &lt;h2&gt;Devfile updates&lt;/h2&gt; &lt;p&gt;We updated the set of devfiles provided with CodeReady Workspaces for more recent versions of runtime images and stacks.&lt;/p&gt; &lt;p&gt;Look for a new devfile with &lt;a href="https://developers.redhat.com/products/eap/overview"&gt;Red Hat JBoss Enterprise Application Platform&lt;/a&gt; (JBoss EAP) XP 1.0, OpenJDK 11, and Maven 3.5. Wherever possible, we migrated the Java-based devfiles to JDK 11. (JBoss EAP is not included with these unless it is required.) We also updated the commands within devfiles with numbers that reflect the recommended sequence of their execution.&lt;/p&gt; &lt;h2&gt;IDE plugin updates&lt;/h2&gt; &lt;p&gt;We updated various IDE plugins provided with CodeReady Workspaces for their newer versions. Plugins for &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; language support, &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/items?itemName=redhat.fabric8-analytics"&gt;application dependency analytics&lt;/a&gt;, project initializer, &lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt; language support, and Sonarlint have all been updated.&lt;/p&gt; &lt;h2&gt;Get CodeReady Workspaces 2.3&lt;/h2&gt; &lt;p&gt;CodeReady Workspaces 2.3 is available now on OpenShift 3.11 and OpenShift 4.x:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;If you are using OpenShift 3.11, you can &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.0/html/installation_guide/installing-codeready-workspaces-on-openshift-3-using-the-operator_crw"&gt;find installation instructions here&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;If you are using OpenShift 4.x, you can install directly from the OpenShift OperatorHub and &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.3/html/installation_guide/installing_codeready_workspaces_on_openshift_container_platform"&gt;follow the documentation here&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/products/codeready-workspaces/download"&gt;Download&lt;/a&gt; the CodeReady Workspaces command-line interface.&lt;/li&gt; &lt;li&gt;Check out the CodeReady Workspaces product page.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#038;title=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" data-a2a-url="https://developers.redhat.com/blog/2020/08/21/improved-configuration-and-more-in-red-hat-codeready-workspaces-2-3/" data-a2a-title="Improved configuration and more in Red Hat CodeReady Workspaces 2.3"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/improved-configuration-and-more-in-red-hat-codeready-workspaces-2-3/"&gt;Improved configuration and more in Red Hat CodeReady Workspaces 2.3&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/mAGagwrmXjM" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Based on Eclipse Che, Red Hat CodeReady Workspaces (CRW) is a Red Hat OpenShift-native developer environment that supports cloud-native development. CodeReady Workspaces 2.3 is now available. For this release, we focused on improving CRW&amp;#8217;s configuration options, updating to the latest versions of IDE plugins, and adding new devfiles. CodeReady Workspaces 2.3 is available on: OpenShift 3.11 [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/improved-configuration-and-more-in-red-hat-codeready-workspaces-2-3/"&gt;Improved configuration and more in Red Hat CodeReady Workspaces 2.3&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/21/improved-configuration-and-more-in-red-hat-codeready-workspaces-2-3/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">767977</post-id><dc:creator>Parag Dave</dc:creator><dc:date>2020-08-21T07:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/21/improved-configuration-and-more-in-red-hat-codeready-workspaces-2-3/</feedburner:origLink></entry><entry><title>‘Hello, World’ tutorial with Kubernetes Operators</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/9f2Ke3qBFMA/" /><category term="DevOps" /><category term="Go" /><category term="Kubernetes" /><category term="Operator" /><category term="kubernetes operator example" /><category term="kubernetes operator tutorial" /><category term="minikube" /><category term="operator-sdk" /><author><name>dsharma</name></author><id>https://developers.redhat.com/blog/?p=736247</id><updated>2020-08-21T07:00:11Z</updated><published>2020-08-21T07:00:11Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; Operators reduce the work of human operators or site reliability engineers. Rather than a half-baked definition, I refer you to this original definition from the creators of the Kubernetes &lt;a href="https://developers.redhat.com/topics/kubernetes/operators/"&gt;Operator&lt;/a&gt; Framework: &lt;a target="_blank" rel="nofollow" href="https://coreos.com/blog/introducing-operator-framework"&gt;&lt;em&gt;Operators are Kubernetes applications&lt;/em&gt;.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;When I started building Operators with the &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-sdk"&gt;operator-sdk&lt;/a&gt; I discovered several unknowns that were difficult to address. I decided to create a guided introduction to the Kubernetes Operator SDK.&lt;/p&gt; &lt;p&gt;Hang on tight.&lt;/p&gt; &lt;h2&gt;Getting started with Kubernetes Operators&lt;/h2&gt; &lt;p&gt;Developers use the Kubernetes Operator SDK to make and deploy complex applications in Kubernetes. In this article, for the sake of brevity and understanding, we will create a simple, &lt;a href="https://developers.redhat.com/blog/2020/06/26/migrating-a-namespace-scoped-operator-to-a-cluster-scoped-operator/"&gt;namespace-scoped Operator&lt;/a&gt; in &lt;a target="_blank" rel="nofollow" href="https://golang.org/"&gt;Golang&lt;/a&gt;. We will build a deployment and set up a service. We&amp;#8217;ll also create a custom controller reconciliation loop that will watch over our deployed resources.&lt;/p&gt; &lt;p&gt;The prerequisites for this guided journey are as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Be familiar with any programming language, though knowledge of Golang will be helpful for this example.&lt;/li&gt; &lt;li&gt;Have &lt;a target="_blank" rel="nofollow" href="https://github.com/kubernetes/minikube"&gt;Minikube&lt;/a&gt; installed in your development environment&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Set up your environment&lt;/h2&gt; &lt;p&gt;We will start by installing the utilities we need to build the Operator.&lt;/p&gt; &lt;h3&gt;Set up Golang&lt;/h3&gt; &lt;p&gt;We will use Golang to build the Operator. &lt;a target="_blank" rel="nofollow" href="https://golang.org/dl/"&gt;Install Golang&lt;/a&gt;, and then configure the following environment settings, as well as any other settings that you prefer:&lt;/p&gt; &lt;pre&gt;$GOPATH=/your/preferred/path/ $GO111MODULE=on &lt;/pre&gt; &lt;p&gt;Next, verify the installation:&lt;/p&gt; &lt;pre&gt;# Verify $ go version go version go1.13.3 linux/amd64 &lt;/pre&gt; &lt;h3&gt;Set up the SDK&lt;/h3&gt; &lt;p&gt;We will use the Kubernetes Operator SDK to build our Operator. &lt;a target="_blank" rel="nofollow" href="https://v0-19-x.sdk.operatorframework.io/docs/install-operator-sdk/"&gt;Install the Operator SDK&lt;/a&gt;, then verify the installation:&lt;/p&gt; &lt;pre&gt;# Verify $ operator-sdk version operator-sdk version: "v0.17.0", commit: "2fd7019f856cdb6f6618e2c3c80d15c3c79d1b6c", kubernetes version: "unknown", go version: "go1.13.10 linux/amd64" &lt;/pre&gt; &lt;h2&gt;Build the Operator&lt;/h2&gt; &lt;p&gt;In this section, we&amp;#8217;ll build the Operator. After each instruction, I will share the file tree for the example so far. Please verify the file tree at each step to ensure that you are in sync with the example.&lt;/p&gt; &lt;h3&gt;Generate the example application code&lt;/h3&gt; &lt;p&gt;Head over to &lt;code&gt;$GOPATH/src/operators&lt;/code&gt; and run:&lt;/p&gt; &lt;pre&gt;$ operator-sdk new hello-operator &lt;/pre&gt; &lt;p&gt;This command generates the boilerplate code for our example application. The default Operator type is GO.&lt;/p&gt; &lt;p&gt;At this point, &lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/tree/c7ec102fc9940af906fdc066902f129e2d578801"&gt;your file tree should look like this&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Add a custom resource definition&lt;/h3&gt; &lt;p&gt;We use custom resource definitions (CRDs) to introduce custom resources that are understandable by k8s deployments. The CRD for this example is as follows:&lt;/p&gt; &lt;pre&gt;$ operator-sdk add api --api-version=example.com/v1alpha1 --kind=Traveller &lt;/pre&gt; &lt;p&gt;Note that we use &lt;code&gt;api-version&lt;/code&gt;to connect to the example application&amp;#8217;s namespace Operator. The format is group/version. The &lt;code&gt;kind&lt;/code&gt; definition refers to custom &lt;code&gt;kind&lt;/code&gt; for the application example. It will be used by the custom resources (CRs) that we create next.&lt;/p&gt; &lt;p&gt;Your file tree &lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/tree/39219cd2317be4390c46d335875ac70fdb8fec03"&gt;should now look like this&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Update the custom resources&lt;/h3&gt; &lt;p&gt;Specifications (specs) are like hardcoded configuration values, also known as the &lt;i&gt;desired state&lt;/i&gt; of the cluster. In order to create the specs for this example, we will edit the custom resources in two files.&lt;/p&gt; &lt;h4&gt;Update example.com_v1alpha1_traveller_cr.yaml&lt;/h4&gt; &lt;p&gt;In this file, we can add any custom values that we might need for our controller function. Here, we will add the Hello Kubernetes image created by Paul Bouwer. Figure 1 shows the updated file, which you can find at &lt;strong&gt;deploy &amp;#62; crds &amp;#62; example.com_v1alpha1_traveller_cr.yaml&lt;/strong&gt;.&lt;/p&gt; &lt;div id="attachment_756247" style="width: 429px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-756247" class="wp-image-756247 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_5oHAQxw85LpAKrnD2njS8g.png" alt="A screenshot of the example.com_v1alpha1_traveller_cr.yaml file." width="419" height="193" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_5oHAQxw85LpAKrnD2njS8g.png 419w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_5oHAQxw85LpAKrnD2njS8g-300x138.png 300w" sizes="(max-width: 419px) 100vw, 419px" /&gt;&lt;p id="caption-attachment-756247" class="wp-caption-text"&gt;Figure 1: Add custom values for the controller function.&lt;/p&gt;&lt;/div&gt; &lt;figure class="graf graf--figure"&gt;&lt;/figure&gt; &lt;h4&gt;Update traveller_types.go&lt;/h4&gt; &lt;p&gt;We use this file to bring custom values to the controllers. The variables are case sensitive, so keep the title case for all variables. For example:&lt;/p&gt; &lt;pre&gt;{Variable} {type} {json:"name in *_cr.yaml" }&lt;/pre&gt; &lt;p&gt;Figure 2 shows the updates to bring custom values to the controllers. This file should be in &lt;strong&gt;pkg &amp;#62; apis &amp;#62; example &amp;#62; v1aplha1 &amp;#62; traveller_types.go&lt;/strong&gt;.&lt;/p&gt; &lt;div id="attachment_763717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA.png"&gt;&lt;img aria-describedby="caption-attachment-763717" class="wp-image-763717 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA-1024x168.png" alt="A screenshot of the traveller_types.go file." width="640" height="105" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA-1024x168.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA-300x49.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA-768x126.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA.png 1200w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-763717" class="wp-caption-text"&gt;Figure 2: Add custom values to the controllers.&lt;/p&gt;&lt;/div&gt; &lt;figure&gt;&lt;/figure&gt; &lt;p&gt;To update the generated code for the given resource type, run the following:&lt;/p&gt; &lt;pre&gt;$ operator-sdk generate k8s &lt;/pre&gt; &lt;p&gt;After each edit in &lt;code&gt;*_types.go&lt;/code&gt;, you must update the CRD to add Open API validations against the newly introduced values. This process is completely automated, simply by entering the following command:&lt;/p&gt; &lt;pre&gt;$ operator-sdk generate crds &lt;/pre&gt; &lt;p&gt;You should now see &lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/commit/bdf9f30d63855aa073a362e7c9414397454cdc7d"&gt;this diff&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Add the controller&lt;/h2&gt; &lt;p&gt;Controllers define the reconciliation logic and the cluster resources to watch. Any change in a resource that is being watched triggers a reconciliation in the controller. Here is the command to add the controller to your Operator SDK:&lt;/p&gt; &lt;pre&gt;&amp;#62;$ operator-sdk add controller --api-version=example.com/v1alpha1 --kind=Traveller&lt;/pre&gt; &lt;p&gt;As always, &lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/commit/c6bed9a53486ec35a04248b91ea501e970ee410e"&gt;verify the code diff&lt;/a&gt; before moving on.&lt;/p&gt; &lt;p&gt;We added the controller with default settings, namely the default APIs, role-based access control (RBAC), and service accounts. Next, we will add the custom logic for creating the application deployment and services. Whatever logic we write should be &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Idempotence"&gt;idempotent&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Add custom logic to the Operator SDK&lt;/h2&gt; &lt;p&gt;We will add five custom functions to the Operator SDK:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/77cf069f74a364405faf03424deefe96ee9d0b22/pkg/controller/traveller/traveller_controller.go#L162-L199"&gt;backendDeployment&lt;/a&gt;: Deploys the pod and exposes it at port 8080.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/77cf069f74a364405faf03424deefe96ee9d0b22/pkg/controller/traveller/traveller_controller.go#L201-L233"&gt;backendService&lt;/a&gt;: Creates a new back-end service for the exposed port.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/77cf069f74a364405faf03424deefe96ee9d0b22/pkg/controller/traveller/traveller_controller.go#L235-L267"&gt;ensureDeployment&lt;/a&gt;: Ensures the presence of a deployment in the given namespace. Otherwise, it creates a deployment by calling &lt;code&gt;1&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/77cf069f74a364405faf03424deefe96ee9d0b22/pkg/controller/traveller/traveller_controller.go#L201-L233"&gt;ensureService&lt;/a&gt;: Ensures the back-end service is present and running in the given namespace. Otherwise, it creates the service by calling &lt;code&gt;2&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/77cf069f74a364405faf03424deefe96ee9d0b22/pkg/controller/traveller/traveller_controller.go#L126-L134"&gt;labels&lt;/a&gt;: Sets the labels on the deployment and pods.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/master/pkg/controller/traveller/traveller_controller.go#L88-L124"&gt;Change the reconcile function&lt;/a&gt; to trigger the newly defined functions.&lt;/p&gt; &lt;p&gt;Your code diff &lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/commit/77cf069f74a364405faf03424deefe96ee9d0b22"&gt;should now look like this&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Test the Operator locally&lt;/h2&gt; &lt;p&gt;We are done adding our custom logic and building up the functionality. Now, we will test the Operator locally:&lt;/p&gt; &lt;pre&gt;# Please deploy in Sequence only $ kubectl apply -f deploy/role.yaml $ kubectl apply -f deploy/service_account.yaml $ kubectl apply -f deploy/role_binding.yaml $ kubectl apply -f deploy/crds/example.com_travellers_crd.yaml $ kubectl apply -f deploy/crds/*_cr.yaml &lt;/pre&gt; &lt;p&gt;Assuming that all of the above artifacts deploy successfully, we can run the Operator locally:&lt;/p&gt; &lt;pre&gt;$ operator-sdk run up --local &lt;/pre&gt; &lt;p&gt;This command should start up the Operator. Make sure that all of the custom resources are deployed by checking them against the namespace. For brevity, we&amp;#8217;re using the default namespace:&lt;/p&gt; &lt;pre&gt;$ kubectl get all&lt;/pre&gt; &lt;p&gt;The results are shown in Figure 3 where k is an alias for kubectl.&lt;/p&gt; &lt;div id="attachment_763737" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_xZbkePASBx2PCLUpc-4Kcg.png"&gt;&lt;img aria-describedby="caption-attachment-763737" class="wp-image-763737" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_xZbkePASBx2PCLUpc-4Kcg.png" alt="the output of kubectl get all" width="640" height="296" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_xZbkePASBx2PCLUpc-4Kcg.png 714w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_xZbkePASBx2PCLUpc-4Kcg-300x139.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-763737" class="wp-caption-text"&gt;Figure 3: Get all Kubernetes resources deployed in the default namespace.&lt;/p&gt;&lt;/div&gt; &lt;figure&gt;&lt;/figure&gt; &lt;h2&gt;Test the service&lt;/h2&gt; &lt;p&gt;Finally, test the service in Minikube by opening up a tunnel:&lt;/p&gt; &lt;pre&gt;$ minikube service backend-service &lt;/pre&gt; &lt;p&gt;The results are shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_763757" style="width: 623px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-763757" class="wp-image-763757 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_pXvimQD1cUe2-LnxjmvxVg.png" alt="A Screnshot for terminal window showing expected output of command. " width="613" height="133" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_pXvimQD1cUe2-LnxjmvxVg.png 613w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_pXvimQD1cUe2-LnxjmvxVg-300x65.png 300w" sizes="(max-width: 613px) 100vw, 613px" /&gt;&lt;p id="caption-attachment-763757" class="wp-caption-text"&gt;Figure 4: Get endpoint for backend-service deployed in Minikube.&lt;/p&gt;&lt;/div&gt; &lt;figure&gt;&lt;/figure&gt; &lt;p&gt;The Minikube tunnel should redirect us to the service that we just created:&lt;/p&gt; &lt;div id="attachment_756187" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-756187" class="wp-image-756187 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_30D09VyYFygRqLwvURjelg-1024x289.png" alt="A screenshot of the home screen for the 'Hello, world' Kubernetes application" width="640" height="181" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_30D09VyYFygRqLwvURjelg-1024x289.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_30D09VyYFygRqLwvURjelg-300x85.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_30D09VyYFygRqLwvURjelg-768x217.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-756187" class="wp-caption-text"&gt;Figure 5: Home screen for the &amp;#8216;Hello, world&amp;#8217; Kubernetes application.&lt;/p&gt;&lt;/div&gt; &lt;figure&gt;&lt;/figure&gt; &lt;p&gt;And that&amp;#8217;s it! You have just developed a basic Kubernetes Operator.&lt;/p&gt; &lt;h2&gt;Export the Operator&lt;/h2&gt; &lt;p&gt;For a real cluster deployment, you would also need to export the Operator:&lt;/p&gt; &lt;pre&gt;$ operator-sdk build docker_username/repo:v0.0.1 $ docker push docker_username/repo $ sed -i "" 's|REPLACE_IMAGE|quay.io/example/memcached-operator:v0.0.1|g' deploy/operator.yaml $ kubectl apply -f deploy/operator.yaml &lt;/pre&gt; &lt;p&gt;Once you export the Operator, you can publish it via Git or Source Control Management (SCM), zip and mail it, or whatever you need to do.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;I again want to emphasize that Operators exist to simplify complex application deployments on Kubernetes. Operators especially support day-to-day activities like upgrading and downgrading Kubernetes applications and more. The guided exercise in this article is a good starting point for working with Operators. See the references below to learn more. Also, check out the GitHub repository for this tutorial, &lt;i&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator"&gt;Basic Operator for Beginners&lt;/a&gt;&lt;/i&gt;, which includes the complete example code for this article.&lt;/p&gt; &lt;h2&gt;Further references&lt;/h2&gt; &lt;p&gt;These additional references are useful for learning about Kubernetes Operators and the Operator Framework:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/books/kubernetes-operators/old/"&gt;&lt;i&gt;Kubernetes Operators: Automating the Container Orchestration Platform&lt;/i&gt;&lt;/a&gt; (O&amp;#8217;Reilly, April 2020)&lt;/li&gt; &lt;li&gt;Source code for the example application used in this article, &lt;a target="_blank" rel="nofollow" href="https://github.com/paulbouwer/hello-kubernetes/"&gt;Hello Kubernetes!&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#038;title=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" data-a2a-url="https://developers.redhat.com/blog/2020/08/21/hello-world-tutorial-with-kubernetes-operators/" data-a2a-title="‘Hello, World’ tutorial with Kubernetes Operators"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/hello-world-tutorial-with-kubernetes-operators/"&gt;&amp;#8216;Hello, World&amp;#8217; tutorial with Kubernetes Operators&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/9f2Ke3qBFMA" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Kubernetes Operators reduce the work of human operators or site reliability engineers. Rather than a half-baked definition, I refer you to this original definition from the creators of the Kubernetes Operator Framework: Operators are Kubernetes applications. When I started building Operators with the operator-sdk I discovered several unknowns that were difficult to address. I decided [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/hello-world-tutorial-with-kubernetes-operators/"&gt;&amp;#8216;Hello, World&amp;#8217; tutorial with Kubernetes Operators&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">736247</post-id><dc:creator>dsharma</dc:creator><dc:date>2020-08-21T07:00:11Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/21/hello-world-tutorial-with-kubernetes-operators/</feedburner:origLink></entry><entry><title>Sunsetting Louketo Project</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/iyfLkb-zu-8/sunsetting-louketo-project.adoc.html" /><category term="feed_group_name_keycloak" scheme="searchisko:content:tags" /><category term="feed_name_keycloak" scheme="searchisko:content:tags" /><author><name>Bruno Oliveira</name></author><id>searchisko:content:id:jbossorg_blog-sunsetting_louketo_project</id><updated>2020-08-21T00:00:00Z</updated><published>2020-08-21T00:00:00Z</published><content type="html">&lt;div class="paragraph"&gt; &lt;p&gt;After careful consideration, we have decided to pull the plug on Louketo and start the EOL procedure. The plan is during the next 3 months to fix only critical bugs and security issues. Everyone interested in capabilities provided by Louketo Proxy should look at &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy"&gt;OAuth2 Proxy&lt;/a&gt; project which is providing a similar set of capabilities and has a healthy and active community.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;a href="https://groups.google.com/g/keycloak-dev/c/oDyw94BWxM0/m/zc0J9R10BwAJ"&gt;A few months ago&lt;/a&gt;, the Keycloak team started Louketo — a joint effort to build a generic OAuth2 Proxy and possibly also begin an umbrella project for a set of OIDC related integration libraries. The initial set of goals has not worked out. Keycloak Gatekeeper and OAuth2 Proxy projects hoped to merge and join efforts but for various reasons, this has not worked out.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;With Louketo and OAuth2 proxy providing similar features, OAuth Proxy being a more popular project with a bigger community we reached a conclusion there&amp;#8217;s no reason to put more effort into Louketo, when we can just contribute there.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;What does it mean in practice?&lt;/p&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_faq"&gt;FAQ&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="sect2"&gt; &lt;h3 id="_will_louketo_proxy_be_no_longer_maintained_will_there_be_no_new_releases"&gt;Will Louketo Proxy be no longer maintained? Will there be no new releases?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Critical bug fixes will be merged and micro releases provided for the next 3 months. It is up to community members to step up and take over maintaining and driving this project further if they wish to do so. Please comment on the &lt;a href="https://github.com/louketo/louketo-proxy/issues/683"&gt;GitHub issue&lt;/a&gt; or contact the Keycloak team on the &lt;a href="https://groups.google.com/forum/#!forum/louketo"&gt;mailing list&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_are_there_any_alternatives_i_should_use_instead"&gt;Are there any alternatives I should use instead?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;OAuth2 Proxy is very close in a set of capabilities to Louketo Proxy and we highly suggest you investigate it as a replacement.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_how_do_i_migrate_to_oauth2_proxy"&gt;How do I migrate to OAuth2 Proxy?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;We’ll provide high-level guidance on how to migrate. Although unfortunately there is no comprehensive guide nor magical script. Some corner cases, specific configurations, and capabilities may not be fully covered or addressed in exactly the same way.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_why_are_you_abandoning_louketo_proxy_as_a_project"&gt;Why are you abandoning Louketo Proxy as a project?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Initial goals failed. Which were merging with OAuth2 Proxy and creating a wider set of OAuth2/OIDC integration libraries. Some individuals originally interested in collaboration took a step back. The end result is the Louketo project duplicating efforts and capabilities of other much more popular projects - OAuth2 Proxy. As we believe in OpenSource we just don’t want to follow NIH syndrome :)&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_i_would_like_to_keep_maintaining_louketo_what_should_i_do"&gt;I would like to keep maintaining Louketo - what should I do?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Please comment on the &lt;a href="https://github.com/louketo/louketo-proxy/issues/683"&gt;GitHub issue&lt;/a&gt; so others can join the discussion. We’ll take it from there :)&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_what_happens_if_nobody_will_step_up_to_maintain_louketo"&gt;What happens if nobody will step up to maintain Louketo?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;After 3 months Louketo repository will be archived and made read-only.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/iyfLkb-zu-8" height="1" width="1" alt=""/&gt;</content><summary>After careful consideration, we have decided to pull the plug on Louketo and start the EOL procedure. The plan is during the next 3 months to fix only critical bugs and security issues. Everyone interested in capabilities provided by Louketo Proxy should look at OAuth2 Proxy project which is providing a similar set of capabilities and has a healthy and active community. A few months ago, the Keycl...</summary><dc:creator>Bruno Oliveira</dc:creator><dc:date>2020-08-21T00:00:00Z</dc:date><feedburner:origLink>https://www.keycloak.org//2020/08/sunsetting-louketo-project.adoc.html</feedburner:origLink></entry><entry><title>JSON logging updates in Open Liberty 20.0.0.8</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Pri5hgLTv7E/" /><category term="DevOps" /><category term="Java" /><category term="Kubernetes" /><category term="Microservices" /><category term="ELK Stack" /><category term="http to json" /><category term="log analysis" /><category term="logformat" /><category term="OpenLiberty" /><author><name>Jakub Pomykala</name></author><id>https://developers.redhat.com/blog/?p=760857</id><updated>2020-08-20T07:00:01Z</updated><published>2020-08-20T07:00:01Z</published><content type="html">&lt;p&gt;With Open Liberty 20.0.0.8, you can now customize HTTP access log fields in JSON logs. This feature allows you to include fields from the &lt;code&gt;accessLogging logFormat&lt;/code&gt; attribute in your JSON logs. You also can write a JSON log file directly to &lt;code&gt;system.out&lt;/code&gt;, without wrapping it in a &lt;code&gt;liberty_message&lt;/code&gt; event.&lt;/p&gt; &lt;p&gt;I&amp;#8217;ll introduce these new features and get you started with using them in &lt;a target="_blank" rel="nofollow" href="https://openliberty.io/about"&gt;Open Liberty&lt;/a&gt; 20.0.0.8. To see the list of fixed bugs, visit the &lt;a href="https://github.com/OpenLiberty/open-liberty/issues?q=label%3Arelease%3A20008+label%3A%22release+bug%22+"&gt;GitHub repository for Open Liberty 20.0.0.8&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;How to run your apps with Open Liberty 20.0.0.8&lt;/h2&gt; &lt;p&gt;If you&amp;#8217;re using &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//guides/maven-intro.html"&gt;Maven&lt;/a&gt;, update the following coordinates to run your apps with Open Liberty 20.0.0.8:&lt;/p&gt; &lt;pre&gt; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;io.openliberty&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;openliberty-runtime&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;20.0.0.8&amp;#60;/version&amp;#62; &amp;#60;type&amp;#62;zip &amp;#60;/type&amp;#62; &amp;#60;/dependency&amp;#62; &lt;/pre&gt; &lt;p&gt;If you&amp;#8217;re using &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//guides/gradle-intro.html"&gt;Gradle&lt;/a&gt;, enter:&lt;/p&gt; &lt;pre&gt;dependencies { libertyRuntime group: 'io.openliberty', name: 'openliberty-runtime', version: '[20.0.0.8,)' } &lt;/pre&gt; &lt;p&gt;If you&amp;#8217;re using docker, enter:&lt;/p&gt; &lt;pre&gt;FROM open-liberty &lt;/pre&gt; &lt;p&gt;See the &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//downloads/"&gt;Open Liberty downloads page&lt;/a&gt; for a downloadable archive of Open Liberty 20.0.0.8.&lt;/p&gt; &lt;h2&gt;Customize HTTP access log fields in your JSON logs&lt;/h2&gt; &lt;p&gt;In Open Liberty, you have the option to format your server logs in either basic or JSON format. When logs are in JSON format, you must specify the sources (&lt;code&gt;message&lt;/code&gt;, &lt;code&gt;trace&lt;/code&gt;, &lt;code&gt;accessLog&lt;/code&gt;, &lt;code&gt;ffdc&lt;/code&gt;, or &lt;code&gt;audit&lt;/code&gt;) that you want to send to &lt;code&gt;messages.log&lt;/code&gt; or &lt;code&gt;console.log&lt;/code&gt; and &lt;code&gt;standard-out&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;In Open Liberty 20.0.0.8, we&amp;#8217;ve added the option to include fields from the &lt;code&gt;accessLogging logFormat&lt;/code&gt; attribute in your JSON logs. Previously, only selected fields were printed in these logs. Now, you can include other NCSA (National Center for Supercomputing Applications) access log fields in your JSON logs. This new feature lets you receive more informative logs that suit your needs.&lt;/p&gt; &lt;h3&gt;Customizing JSON access log fields&lt;/h3&gt; &lt;p&gt;When logs are in JSON format, you can use the new &lt;code&gt;jsonAccessLogFields&lt;/code&gt; logging attribute to specify whether you want your access logs to have the default set of fields or a custom set based on the HTTP &lt;code&gt;accessLogging logFormat&lt;/code&gt; attribute. You can use the &lt;code&gt;accessLogging logFormat&lt;/code&gt; attribute to define the log fields that you want. You can then send the logs to a log analysis tool, such as the ELK (Elasticsearch, Logstash, Kibana) stack.&lt;/p&gt; &lt;p&gt;As an example, you might specify that you wanted the user ID and request-time fields in your JSON access logs. You could then filter these fields by user ID in Kibana and track performance on a user-by-user basis.&lt;/p&gt; &lt;p&gt;To receive access logs, you must set the property &lt;code&gt;accessLogging&lt;/code&gt; or &lt;code&gt;httpAccessLogging&lt;/code&gt;. For example, you might set the following attributes in your &lt;code&gt;server.xml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &amp;#60;httpEndpoint id="defaultHttpEndpoint" httpPort="9080" httpsPort="9443" host="*"&amp;#62; &amp;#60;accessLogging logFormat='%R{W} %u %{my_cookie}C %s'/&amp;#62; &amp;#60;/httpEndpoint&amp;#62; &amp;#60;logging messageFormat="json" messageSource="message,accessLog" jsonAccessLogFields="logFormat"/&amp;#62; &lt;/pre&gt; &lt;p&gt;In the &lt;code&gt;messages.log&lt;/code&gt; file, your access logs would now contain the four fields specified in the &lt;code&gt;accessLogging logFormat&lt;/code&gt; attribute (elapsed time, user ID, cookie, and response code):&lt;/p&gt; &lt;pre&gt;{ "type": "liberty_accesslog", "host": "192.168.1.15", "ibm_userDir": "/you/jennifer.zhen.chengibm.com/libertyGit/open-liberty/dev/build.image/wlp/usr/", "ibm_serverName": "defaultServer", "ibm_cookie_my_cookie": "example_cookie", "ibm_responseCode": 200, "ibm_datetime": "2020-06-18T09:30:47.693-0400", "ibm_sequence": "1592487047653_0000000000001" } &lt;/pre&gt; &lt;p&gt;You can also integrate this new functionality with Open Liberty&amp;#8217;s &lt;code&gt;logstashCollector-1.0&lt;/code&gt; feature by adding the following to your &lt;code&gt;server.xml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &amp;#60;featureManager&amp;#62; &amp;#60;feature&amp;#62;logstashCollector-1.0&amp;#60;/feature&amp;#62; &amp;#60;/featureManager&amp;#62; &amp;#60;logstashCollector jsonAccessLogFields="logFormat"&amp;#62; &amp;#60;/logstashCollector&amp;#62; &lt;/pre&gt; &lt;h3&gt;Complete list of the new access log fields&lt;/h3&gt; &lt;p&gt;This table describes the new fields available with the corresponding &lt;code&gt;logFormat&lt;/code&gt; token:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Field&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;logFormat token&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_remoteIP&lt;/td&gt; &lt;td&gt;Remote IP address; e.g., 127.0.0.1.&lt;/td&gt; &lt;td&gt;%a&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_bytesSent&lt;/td&gt; &lt;td&gt;Response size in bytes excluding headers.&lt;/td&gt; &lt;td&gt;%b&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_cookie_{cookiename}&lt;/td&gt; &lt;td&gt;Cookie value from the request.&lt;/td&gt; &lt;td&gt;%{cookieName}C or %C&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_requestElapsedTime&lt;/td&gt; &lt;td&gt;The elapsed time of the request: millisecond accuracy, microsecond precision.&lt;/td&gt; &lt;td&gt;%D&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_requestHeader_{headername}&lt;/td&gt; &lt;td&gt;Header value from the request.&lt;/td&gt; &lt;td&gt;%{headerName}i&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_responseHeader_{headername}&lt;/td&gt; &lt;td&gt;Header value from the response.&lt;/td&gt; &lt;td&gt;%{headerName}o&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_requestFirstLine&lt;/td&gt; &lt;td&gt;The first line of the request.&lt;/td&gt; &lt;td&gt;%r&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_requestStartTime&lt;/td&gt; &lt;td&gt;The start time of the request, in NCSA format.&lt;/td&gt; &lt;td&gt; &lt;p class="tableblock"&gt;%t&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_accessLogDatetime&lt;/td&gt; &lt;td&gt;The time when the message to the access log is queued to be logged, in normal NCSA format.&lt;/td&gt; &lt;td&gt;%{t}W&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_remoteUserID&lt;/td&gt; &lt;td&gt;Remote user according to the WebSphere Application Server specific $WSRU header.&lt;/td&gt; &lt;td&gt;%u&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;See the documentation for &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//docs/ref/config/#logging.html"&gt;Open Liberty logging&lt;/a&gt;, and &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//docs/20.0.0.7/log-trace-configuration.html"&gt;Open Liberty log and trace configuration&lt;/a&gt; for more information.&lt;/p&gt; &lt;h2&gt;Write pre-formatted JSON application logs directly to &lt;code&gt;System.out&lt;/code&gt; or &lt;code&gt;System.err&lt;/code&gt;&lt;/h2&gt; &lt;p&gt;Prior to this release, Open Liberty embedded any pre-formatted JSON application logs written to &lt;code&gt;System.out&lt;/code&gt; or &lt;code&gt;System.err&lt;/code&gt; into the message field of a &lt;code&gt;liberty_message&lt;/code&gt; event. Now, you can write these logs directly to &lt;code&gt;System.out&lt;/code&gt; or &lt;code&gt;System.err&lt;/code&gt; without having them wrapped in a &lt;code&gt;liberty_message&lt;/code&gt; event. You can then send the logs to a log analysis tool, such as the ELK (Elasticsearch, Logstash, Kibana) stack.&lt;/p&gt; &lt;p&gt;Here&amp;#8217;s an example of a pre-formatted JSON log prior to this release:&lt;/p&gt; &lt;pre&gt;{ "type":"liberty_message", "host":"192.168.0.119", "ibm_userDir":"\/you\/yushan.lin@ibm.com\/Documents\/archived-guide-log4j\/finish\/target\/liberty\/wlp\/usr\ ", "ibm_serverName":"log4j.sampleServer", "message":"{\n \"timeMillis\" : 1587666082123,\n \"thread\" : \"Default Executor-thread-8\",\n \"level\" : \"WARN\",\n \"loggerName\" : \"application.servlet.LibertyServlet\",\n \"message\" : \"hello liberty servlet warning message!\",\n \"endOfBatch\" : false,\n \"loggerFqcn\" : \"org.apache.logging.log4j.spi.AbstractLogger\",\n \"threadId\" : 53,\n \"threadPriority\" : 5\n}\r", "ibm_threadId":"00000035", "ibm_datetime":"2020-04-23T14:21:22.124-0400", "module":"SystemOut", "loglevel":"SystemOut", "ibm_methodName":"", "ibm_className":"", "ibm_sequence":"1587666082124_000000000001B", "ext_thread":"Default Executor-thread-8” } &lt;/pre&gt; &lt;p&gt;You can now output the JSON application logs so that they are not wrapped in &lt;code&gt;liberty_message&lt;/code&gt; events. Enable this functionality by setting &lt;code&gt;appsWriteJson="true"&lt;/code&gt; in the logging element of the &lt;code&gt;server.xml&lt;/code&gt;. Another option is to have it set from the moment the server starts by setting the &lt;code&gt;bootstrap.properties&lt;/code&gt; to: &lt;code&gt;com.ibm.ws.logging.apps.write.json=true&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;For more information about this new logging feature, see &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//docs/ref/config/#logging.html"&gt;Open Liberty logging&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Try Open Liberty 20.0.0.8 in Red Hat Runtimes now&lt;/h2&gt; &lt;p&gt;Open Liberty is part of the Red Hat Runtimes offering and is available to &lt;a href="https://access.redhat.com/products/red-hat-runtimes" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;Red Hat Runtimes subscribers&lt;/a&gt;. To learn more about deploying Open Liberty applications to OpenShift, take a look at our &lt;a href="https://openliberty.io/guides/cloud-openshift.html" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;Open Liberty guide: Deploying microservices to OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#038;title=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" data-a2a-url="https://developers.redhat.com/blog/2020/08/20/json-logging-updates-in-open-liberty-20-0-0-8/" data-a2a-title="JSON logging updates in Open Liberty 20.0.0.8"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/20/json-logging-updates-in-open-liberty-20-0-0-8/"&gt;JSON logging updates in Open Liberty 20.0.0.8&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Pri5hgLTv7E" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;With Open Liberty 20.0.0.8, you can now customize HTTP access log fields in JSON logs. This feature allows you to include fields from the accessLogging logFormat attribute in your JSON logs. You also can write a JSON log file directly to system.out, without wrapping it in a liberty_message event. I&amp;#8217;ll introduce these new features and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/20/json-logging-updates-in-open-liberty-20-0-0-8/"&gt;JSON logging updates in Open Liberty 20.0.0.8&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/20/json-logging-updates-in-open-liberty-20-0-0-8/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">760857</post-id><dc:creator>Jakub Pomykala</dc:creator><dc:date>2020-08-20T07:00:01Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/20/json-logging-updates-in-open-liberty-20-0-0-8/</feedburner:origLink></entry><entry><title>Multipath TCP on Red Hat Enterprise Linux 8.3: From 0 to 1 subflows</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/e_noUn9Fb-Q/" /><category term="DevOps" /><category term="Linux" /><category term="Open source" /><category term="Linux kernel" /><category term="MPTCP" /><category term="networking" /><category term="rhel 8" /><category term="rhel 8.3" /><author><name>Davide Caratti</name></author><id>https://developers.redhat.com/blog/?p=756817</id><updated>2020-08-19T07:00:07Z</updated><published>2020-08-19T07:00:07Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Multipath_TCP"&gt;Multipath TCP&lt;/a&gt; (MPTCP) extends traditional TCP to allow reliable end-to-end delivery over multiple simultaneous TCP paths, and is coming as a tech preview on &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; 8.3. This is the first of two articles for users who want to practice with the new MPTCP functionality on a live system. In this first part, we show you how to enable the protocol in the kernel and let client and server applications use the MPTCP sockets. Then, we run diagnostics on the kernel in a sample test network, where endpoints are using a single subflow.&lt;/p&gt; &lt;h2&gt;Multipath TCP in Red Hat Enterprise Linux 8&lt;/h2&gt; &lt;p&gt;Multipath TCP is a relatively new &lt;a target="_blank" rel="nofollow" href="https://tools.ietf.org/html/rfc8684"&gt;extension&lt;/a&gt; for the Transmission Control Protocol (TCP), and its official Linux implementation is &lt;a target="_blank" rel="nofollow" href="https://twitter.com/davem_dokebi/status/1220715287365943298"&gt;even more recent&lt;/a&gt;. Early users might want to know what to expect in RHEL 8.3. In this article, you will learn how to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Enable the Multipath TCP protocol in the kernel.&lt;/li&gt; &lt;li&gt;Let an application open an &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt; socket.&lt;/li&gt; &lt;li&gt;Use &lt;code&gt;tcpdump&lt;/code&gt; to inspect MPTCP options with live traffic.&lt;/li&gt; &lt;li&gt;Inspect the subflow status with &lt;code&gt;ss&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Enabling Multipath TCP in the kernel&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://www.multipath-tcp.org/"&gt;Multipath TCP&lt;/a&gt; registers as an upper-layer protocol (ULP) for TCP. Users can ensure that &lt;code&gt;mptcp&lt;/code&gt; is available in the kernel by checking the available ULPs:&lt;/p&gt; &lt;pre&gt;# sysctl net.ipv4.tcp_available_ulp net.ipv4.tcp_available_ulp = espintcp mptcp &lt;/pre&gt; &lt;p&gt;Unlike upstream Linux, MPTCP is disabled in the default Red Hat Enterprise Linux (RHEL) 8.3 runtime. To enable the possibility of creating sockets, system administrators need to issue a proper &lt;code&gt;sysctl&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt;# sysctl -w net.mptcp.enabled=1 # sysctl net.mptcp.enabled net.mptcp.enabled = 1 &lt;/pre&gt; &lt;h2&gt;Preparing the system for its first MPTCP socket&lt;/h2&gt; &lt;p&gt;With MPTCP enabled in the RHEL 8.3 kernel, user-space programs have a new protocol available for the &lt;code&gt;socket&lt;/code&gt; system call. There are two potential use cases for the new protocol.&lt;/p&gt; &lt;h3&gt;Native MPTCP applications&lt;/h3&gt; &lt;p&gt;Applications supporting MPTCP natively can open a &lt;code&gt;SOCK_STREAM&lt;/code&gt; socket specifying &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt; as the protocol and &lt;code&gt;AF_INET&lt;/code&gt; or &lt;code&gt;AF_INET6&lt;/code&gt; as the address family:&lt;/p&gt; &lt;pre&gt;fd = socket(AF_INET, SOCK_STREAM, IPPROTO_MPTCP); &lt;/pre&gt; &lt;p&gt;After the application creates a socket, the kernel will operate one or more TCP subflows that will use the standard MPTCP option (&lt;code&gt;IANA number = 30&lt;/code&gt;). Client and server semantics are the same as those used by a regular TCP socket (meaning that they will use &lt;code&gt;bind()&lt;/code&gt;, &lt;code&gt;listen()&lt;/code&gt;, &lt;code&gt;connect()&lt;/code&gt;, and &lt;code&gt;accept()&lt;/code&gt;).&lt;/p&gt; &lt;h3&gt;Legacy TCP applications converted to MPTCP&lt;/h3&gt; &lt;p&gt;Most user-space applications have no knowledge of &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt;, nor would it be realistic to patch and rebuild all of them to add native support for MPTCP. Because of this, the community opted for using an eBPF program that wraps the &lt;code&gt;socket()&lt;/code&gt; system call and &lt;a target="_blank" rel="nofollow" href="https://github.com/multipath-tcp/mptcp_net-next/issues/18"&gt;overrides the value of &lt;code&gt;protocol&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In RHEL 8.3, this program will run on CPU groups so that system administrators can specify which applications should run MPTCP while others continue with TCP. We will discuss the eBPF helper upstream in the next weeks, but we want to support early RHEL 8.3 users who want to try their own applications with MPTCP.&lt;/p&gt; &lt;p&gt;You can use a &lt;a target="_blank" rel="nofollow" href="https://linux.die.net/man/1/stap"&gt;systemtap&lt;/a&gt; script as a workaround to intercept calls to &lt;code&gt;__sys_socket()&lt;/code&gt; in the kernel. You can then allow a kernel probe to replace &lt;code&gt;IPPROTO_TCP&lt;/code&gt; with &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt;. You will need to add packages to install a probe in the kernel with &lt;code&gt;stap&lt;/code&gt;. You&amp;#8217;ll also use the good-old &lt;code&gt;ncat&lt;/code&gt; tool from the &lt;code&gt;nmap-ncat&lt;/code&gt; package to run the client and the server:&lt;/p&gt; &lt;pre&gt;# dnf -y install \ &amp;#62; kernel-headers \ &amp;#62; kernel-devel \ &amp;#62; kernel-debuginfo &amp;#62; kernel-debuginfo-common_x86_64 \ &amp;#62; systemtap-client \ &amp;#62; systemtap-client-devel \ &amp;#62; nmap-ncat &lt;/pre&gt; &lt;p&gt;Use the following command to start the &lt;code&gt;systemtap&lt;/code&gt; &lt;a target="_blank" rel="nofollow" href="https://github.com/multipath-tcp/mptcp_net-next/issues/18#issuecomment-650529642"&gt;script&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;# stap -vg mpctp.stap&lt;/pre&gt; &lt;h3&gt;Protocol smoke test: A single subflow using &lt;code&gt;ncat&lt;/code&gt;&lt;/h3&gt; &lt;p&gt;The test network topology shown in Figure 1 consists of a client and a server that run in separate namespaces, connected through a virtual ethernet device (&lt;code&gt;veth&lt;/code&gt;).&lt;/p&gt; &lt;div id="attachment_757817" style="width: 542px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-757817" class="wp-image-757817 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/mptcp-1-topology.png" alt="Illustration of a network test topology with the veth-ns-client server." width="532" height="147" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/mptcp-1-topology.png 532w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/mptcp-1-topology-300x83.png 300w" sizes="(max-width: 532px) 100vw, 532px" /&gt;&lt;p id="caption-attachment-757817" class="wp-caption-text"&gt;Figure 1: A network topology for basic MPTCP testing.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Adding additional IP addresses will simulate multiple L4 paths between endpoints. First, the server opens a passive socket, listening on a TCP port:&lt;/p&gt; &lt;pre&gt;# ncat -l 192.0.2.1 4321&lt;/pre&gt; &lt;p&gt;Then, the client connects to the server:&lt;/p&gt; &lt;pre&gt;# ncat 192.0.2.1 4321&lt;/pre&gt; &lt;p&gt;From a functional point of view, the interaction is the same as using &lt;code&gt;ncat&lt;/code&gt; with regular TCP: When the user writes a line in the client&amp;#8217;s standard input, the server displays that line in the standard output. Similarly, typing a line in the server&amp;#8217;s standard input results in transmitting it back to the client&amp;#8217;s standard output. In this example, we use &lt;code&gt;ncat&lt;/code&gt; to send a &amp;#8220;&lt;code&gt;hello world (1)\n&lt;/code&gt;&amp;#8221; message to the server. It waits for a second, then sends back &amp;#8220;&lt;code&gt;hello world (2)\n&lt;/code&gt;,&amp;#8221; then it closes the connection.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Current Linux MPTCP does not support mixed IPv4/IPv6 addresses. Therefore, all addresses involved in client/server connectivity must belong to the same family.&lt;/p&gt; &lt;h2&gt;Capturing traffic and examining it with &lt;code&gt;tcpdump&lt;/code&gt;&lt;/h2&gt; &lt;p&gt;The Red Hat Enterprise Linux 8 version of &lt;code&gt;tcpdump&lt;/code&gt; doesn&amp;#8217;t yet support dissecting MPTCP v1 suboptions in TCP headers. We can overcome this problem by building a binary from the upstream repository. Alternatively, we can replace it with a &lt;a target="_blank" rel="nofollow" href="https://copr.fedorainfracloud.org/coprs/dcaratti/tcpdump-mptcp/"&gt;more recent binary&lt;/a&gt;. With either of those changes, it&amp;#8217;s possible to inspect the MPTCP suboption.&lt;/p&gt; &lt;h3&gt;Three-way handshake: The MP_CAPABLE suboption&lt;/h3&gt; &lt;p&gt;During a three-way-handshake, the client and server exchange a 64-bit key using the &lt;code&gt;MP_CAPABLE&lt;/code&gt; suboption, which is visible in the output of &lt;code&gt;tcpdump&lt;/code&gt; in the braces ({}) after &lt;code&gt;mptcp capable&lt;/code&gt;. These keys are then used later to compute the DSN/DACK and token. The &lt;code&gt;MP_CAPABLE&lt;/code&gt; suboption that originates in the client is also present following a successful connection setup. It will be present until the server explicitly acknowledges it using a data sequence signal (DSS) suboption:&lt;/p&gt; &lt;pre&gt;# tcpdump -#tnnr capture.pcap 1 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [S], seq 1721499445, win 29200, options [mss 1460,sackOK,TS val 33385784 ecr 0,nop,wscale 7,mptcp capable v1], length 0 2 IP 192.0.2.1.4321 &amp;#62; 192.0.2.2.44176: Flags [S.], seq 3341831007, ack 1721499446, win 28960, options [mss 1460,sackOK,TS val 4061152149 ecr 33385784,nop,wscale 7,mptcp capable v1 {0xbb206e3023b47a2d}], length 0 3 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [.], ack 1, win 229, options [nop,nop,TS val 33385785 ecr 4061152149,mptcp capable v1 {0x41923206b75835f5,0xbb206e3023b47a2d}], length 0 4 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [P.], seq 1:17, ack 1, win 229, options [nop,nop,TS val 33385785 ecr 4061152149,mptcp capable v1 {0x41923206b75835f5,0xbb206e3023b47a2d},nop,nop], length 16 &lt;/pre&gt; &lt;h3&gt;MPTCP-level sequence numbers: The DSS suboption&lt;/h3&gt; &lt;p&gt;After that, TCP segments will carry the DSS suboption that contains MPTCP sequence numbers. More specifically, we can observe the data sequence number (DSN) and data acknowledgment (DACK) values, as shown here:&lt;/p&gt; &lt;pre&gt;5 IP 192.0.2.1.4321 &amp;#62; 192.0.2.2.44176: Flags [.], ack 17, win 227, options [nop,nop,TS val 4061152149 ecr 33385785,mptcp dss ack 1711754507747579648], length 0 6 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [P.], seq 17:33, ack 1, win 229, options [nop,nop,TS val 33386778 ecr 4061152149,mptcp dss ack 1331650533424046587 seq 1711754507747579648 subseq 17 len 16,nop,nop], length 16 7 IP 192.0.2.1.4321 &amp;#62; 192.0.2.2.44176: Flags [.], ack 33, win 227, options [nop,nop,TS val 4061153142 ecr 33386778,mptcp dss ack 1711754507747579664], length 0 &lt;/pre&gt; &lt;p&gt;Using a single subflow, DSN and DACK increase by the same amount as the TCP sequence and acknowledgment numbers. When the connection ends, the subflows are closed with a &lt;code&gt;FIN&lt;/code&gt; packet, just like regular TCP flows would be. Because it also closes the MPTCP socket, the data &lt;code&gt;fin&lt;/code&gt; bit is set in the DSS suboption, as shown here:&lt;/p&gt; &lt;pre&gt;8 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [F.], seq 33, ack 1, win 229, options [nop,nop,TS val 33387798 ecr 4061153142,mptcp dss fin ack 1331650533424046587 seq 1711754507747579664 subseq 0 len 1,nop,nop], length 0 9 IP 192.0.2.1.4321 &amp;#62; 192.0.2.2.44176: Flags [.], ack 34, win 227, options [nop,nop,TS val 4061154203 ecr 33387798,mptcp dss ack 1711754507747579664], length 0 10 IP 192.0.2.1.4321 &amp;#62; 192.0.2.2.44176: Flags [F.], seq 1, ack 34, win 227, options [nop,nop,TS val 4061162156 ecr 33387798,mptcp dss fin ack 1711754507747579664 seq 1331650533424046587 subseq 0 len 1,nop,nop], length 0 11 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [.], ack 2, win 229, options [nop,nop,TS val 33395793 ecr 4061162156,mptcp dss ack 1331650533424046587], length 0&lt;/pre&gt; &lt;h2&gt;Inspecting subflow data with &lt;code&gt;ss&lt;/code&gt;&lt;/h2&gt; &lt;p&gt;Because MPTCP uses TCP as a transport protocol, network administrators can query the kernel to retrieve information on TCP connections that are being used by the main MPTCP socket. In this example, we&amp;#8217;re running &lt;code&gt;ss&lt;/code&gt; on the client filtering on the server listening port, where information relevant to MPTCP can be read after &lt;code&gt;tcp-ulp-mptcp&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;# ss -nti '( dport :4321 )' dst 192.0.2.1 State Recv-Q Send-Q Local Address:Port Peer Address:PortProcess ESTAB 0 0 192.0.2.2:44176 192.0.2.1:4321 cubic wscale:7,7 [...] bytes_sent:32 bytes_acked:33 [...] tcp-ulp-mptcp flags:Mmec token:0000(id:0)/768f615c(id:0) seq:127af91ad1b321fb sfseq:1 ssnoff:c7304b5f maplen:0 &lt;/pre&gt; &lt;h3&gt;SS command output explained&lt;/h3&gt; &lt;p&gt;The line below &lt;code&gt;tcp-ulp-mptcp&lt;/code&gt; is the output of &lt;code&gt;ss&lt;/code&gt; in the client namespace immediately following the transmission of packet 6 in the previous section:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Each value of &lt;code&gt;token&lt;/code&gt; is the truncated Hashed Message Authentication Code algorithm (HMAC) of the remote peer&amp;#8217;s key, which the client receives during the three-way handshake. Further &lt;code&gt;MP_JOIN SYN&lt;/code&gt; packets will use that value to prove that they have not been spoofed. The &lt;code&gt;id&lt;/code&gt; is the subflow identifier as specified in the RFC. For non-&lt;code&gt;MP_JOIN&lt;/code&gt; sockets, only the local token and ID are available.&lt;/li&gt; &lt;li&gt;&lt;code&gt;flags&lt;/code&gt; is a bitmask containing information on the subflow state. For instance, &lt;code&gt;M/m&lt;/code&gt; records the presence of the &lt;code&gt;MP_CAPABLE&lt;/code&gt; suboption in the three-way handshake. The &lt;code&gt;c&lt;/code&gt; means that the client received the server&amp;#8217;s key (that is, it acknowledged the SYN/ACK), while &lt;code&gt;e&lt;/code&gt; means that the exchange of both MPTCP keys is complete.&lt;/li&gt; &lt;li&gt;&lt;code&gt;seq&lt;/code&gt; denotes the next MPTCP sequence number that the endpoint expects on reception, or, equivalently, the DACK value for the next transmitted packet.&lt;/li&gt; &lt;li&gt;&lt;code&gt;sfseq&lt;/code&gt; is the subflow sequence number, meaning that it is the current TCP ACK value for this subflow.&lt;/li&gt; &lt;li&gt;&lt;code&gt;ssnoff&lt;/code&gt; is the current difference between the TCP sequence number and the MPTCP sequence number for this subflow. If you are using a single subflow, this value will not change during the connection. If you are using more than one subflow to simultaneously carry data segments, then this value can increase or decrease depending on the path capacity.&lt;/li&gt; &lt;li&gt;&lt;code&gt;maplen&lt;/code&gt; indicates how many bytes are left to fill the current DSS map.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Note that we can compute the value of &lt;code&gt;seq&lt;/code&gt; by starting from the server key in the SYN/ACK (which is packet 2 of the capture) and computing the server&amp;#8217;s Initial Data Sequence Number (IDSN), then truncating &lt;code&gt;sha256(ntohll(bb206e3023b47a2d))&lt;/code&gt; to the least-significant 64-bit, as specified by &lt;a target="_blank" rel="nofollow" href="https://tools.ietf.org/html/rfc8684#section-3.3.2"&gt;RFC 8684&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Also note that, because the client is not receiving any data from the server, &lt;code&gt;seq&lt;/code&gt; remains equal to the IDSN  throughout the connection&amp;#8217;s lifetime. For the same reason, the value of &lt;code&gt;sfseq&lt;/code&gt; is constantly equal to 1 in the example. We can see the IDSN in the DSN number of packet 10 and in the DACK number of packets 6 and 8 (in decimal format: &lt;code&gt;1331650533424046587&lt;/code&gt;), as well as in the output of &lt;code&gt;ss&lt;/code&gt; (in hex format: &lt;code&gt;127af91ad1b321fb&lt;/code&gt;). Similarly, in this example the SSN offset (&lt;code&gt;c7304b5f&lt;/code&gt; in the &lt;code&gt;ss&lt;/code&gt; output)  is constantly equal to the initial TCP sequence number (&lt;code&gt;3341831007&lt;/code&gt; in the SYN/ACK, packet 2 of the capture output).&lt;/p&gt; &lt;h2&gt;Conclusion and what&amp;#8217;s next&lt;/h2&gt; &lt;p&gt;In realistic scenarios, MPTCP will generally use more than one subflow. In this way, sockets can preserve connectivity even after an event causes a failure in one of the L4 paths. In the next article, we will show you how to use &lt;code&gt;iproute2&lt;/code&gt; to configure multiple TCP paths on RHEL 8.3, and how to watch &lt;code&gt;ncat&lt;/code&gt; doing multipath for real.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#038;title=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" data-a2a-url="https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows/" data-a2a-title="Multipath TCP on Red Hat Enterprise Linux 8.3: From 0 to 1 subflows"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows/"&gt;Multipath TCP on Red Hat Enterprise Linux 8.3: From 0 to 1 subflows&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/e_noUn9Fb-Q" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Multipath TCP (MPTCP) extends traditional TCP to allow reliable end-to-end delivery over multiple simultaneous TCP paths, and is coming as a tech preview on Red Hat Enterprise Linux 8.3. This is the first of two articles for users who want to practice with the new MPTCP functionality on a live system. In this first part, we [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows/"&gt;Multipath TCP on Red Hat Enterprise Linux 8.3: From 0 to 1 subflows&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">756817</post-id><dc:creator>Davide Caratti</dc:creator><dc:date>2020-08-19T07:00:07Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows/</feedburner:origLink></entry><entry><title>OpenShift 4.5: Bringing developers joy with Kubernetes 1.18 and so much more</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/NbSnXzu6mk8/" /><category term="CI/CD" /><category term="Developer Tools" /><category term="DevOps" /><category term="Java" /><category term="Kubernetes" /><category term="Node.js" /><category term="Python" /><category term="Apache Kafka" /><category term="ci/cd pipeline" /><category term="codeready" /><category term="Knative" /><category term="odo" /><category term="openshift" /><author><name>Steve Speicher</name></author><id>https://developers.redhat.com/blog/?p=764757</id><updated>2020-08-18T07:00:21Z</updated><published>2020-08-18T07:00:21Z</published><content type="html">&lt;p&gt;Since the first &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift&lt;/a&gt; release in 2015, Red Hat has put out numerous releases based on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. Five years later, &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/blog/happy-6th-birthday-kubernetes"&gt;Kubernetes is celebrating its sixth birthday&lt;/a&gt;, and last month, we announced the general availability of &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/blog/openshift-4.5-arrives-bringing-new-supported-installations"&gt;Red Hat OpenShift Container Platform 4.5&lt;/a&gt;. In this article, I offer a high-level view of the latest OpenShift release and its technology and feature updates based on &lt;a href="https://kubernetes.io/blog/2020/03/25/kubernetes-1-18-release-announcement/"&gt;Kubernetes 1.18&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Although OpenShift 4.5 brings many improvements by itself, many other Red Hat contributions enhance the developer experience with this release. Figure 1 shows the range of &lt;a href="https://www.redhat.com/en/about/press-releases/red-hat-advances-kubernetes-across-cloud-native-toolchain-updated-developer-portfolio"&gt;additional technology updates&lt;/a&gt; that improve the operational and development experience when using OpenShift 4.5.&lt;/p&gt; &lt;div id="attachment_764837" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Screen-Shot-2020-08-12-at-2.44.57-PM.png"&gt;&lt;img aria-describedby="caption-attachment-764837" class="wp-image-764837" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Screen-Shot-2020-08-12-at-2.44.57-PM.png" alt="A diagram of technology updates that improve the developer experiencing using OpenShift 4.5." width="640" height="243" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Screen-Shot-2020-08-12-at-2.44.57-PM.png 877w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Screen-Shot-2020-08-12-at-2.44.57-PM-300x114.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Screen-Shot-2020-08-12-at-2.44.57-PM-768x292.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-764837" class="wp-caption-text"&gt;Figure 1: Additional technology updates that improve the operational and development experience using OpenShift 4.5.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: No two developers are the same. Developers have different skill sets, backgrounds, and prefer different development environments. Some developers want to concern themselves with platform details, and some do not. At Red Hat, we focus on meeting developers where they are and providing stability and experience improvements in popular open source projects as part of our developer tooling.&lt;/p&gt; &lt;h2&gt;Platform support&lt;/h2&gt; &lt;p&gt;OpenShift 4.5 includes the Kubernetes 1.18 release, which was focused on fit-and-finish work that provided stability for high-scale operations. Developer experience improvements to OpenShift Container Platform 4.5 include &lt;a href="https://developers.redhat.com/blog/2020/07/16/whats-new-in-the-openshift-4-5-console-developer-experience/"&gt;web console updates&lt;/a&gt;, one-click navigation to add health check probes to your deployments, a unified experience for virtual machines alongside your containers, and easy access to command-line tools in a web terminal. Figure 2 shows the new one-click navigation tool for adding health checks to your deployments.&lt;/p&gt; &lt;div id="attachment_746677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/45-WhatsNew-F03-HealthCheck-Notification-1.png"&gt;&lt;img aria-describedby="caption-attachment-746677" class="wp-image-746677 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/45-WhatsNew-F03-HealthCheck-Notification-1-1024x502.png" alt="A screenshot of the one-click navigation for adding health checks." width="640" height="314" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/45-WhatsNew-F03-HealthCheck-Notification-1-1024x502.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/45-WhatsNew-F03-HealthCheck-Notification-1-300x147.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/45-WhatsNew-F03-HealthCheck-Notification-1-768x377.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-746677" class="wp-caption-text"&gt;Figure 2: One-click health checks for your OpenShift 4.5 deployments.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;OpenShift Serverless&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/serverless/serverless-getting-started.html"&gt;OpenShift Serverless 1.7.2&lt;/a&gt; delivers updates to &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;Knative Serving&lt;/a&gt; 0.13.3, Knative Eventing 0.13.0, and the associated command-line interface (CLI) tool, &lt;code&gt;kn&lt;/code&gt; 0.13.2. Altogether, these updates provide serverless autoscaling to and from zero, flexible traffic routing, and secure connections across your Kubernetes applications. The OpenShift web console enables simple event source creation.&lt;/p&gt; &lt;h3&gt;OpenShift Service Mesh&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/service_mesh/service_mesh_arch/understanding-ossm.html"&gt;OpenShift Service Mesh 1.1.5&lt;/a&gt; brings upgrades to &lt;a href="https://developers.redhat.com/topics/service-mesh"&gt;Istio 1.4.8&lt;/a&gt;, Jaeger stream support via Kafka, and linking to the Kiali web console from OpenShift&amp;#8217;s web console. Istio 1.4 enables automatic mutual TLS sidecar improvements. It also supports users in disconnected environments for offline installation.&lt;/p&gt; &lt;h2&gt;Command-line tooling&lt;/h2&gt; &lt;p&gt;OpenShift 4.5 offers updates for command-line tooling like &lt;code&gt;odo&lt;/code&gt;, Helm, and the &lt;code&gt;oc new-app&lt;/code&gt; command.&lt;/p&gt; &lt;h3&gt;odo&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="http://odo.dev"&gt;odo 2.0&lt;/a&gt; is a CLI for developers who write, build, and deploy applications on OpenShift. It uses a &lt;code&gt;git push&lt;/code&gt;-style syntax that is familiar to developers, is included with OpenShift, and provides a new way for developers to iterate on code. The &lt;code&gt;odo&lt;/code&gt; 2.0 release features support for Kubernetes, as well as OpenShift, and provides an open model for tools through a standard definition and rapid, iterative development. This new model and rapid development are available for &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; using &lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt;, &lt;a href="https://developers.redhat.com/blog/category/node-js/"&gt;Node.js&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/blog/category/python/"&gt;Python&lt;/a&gt; in technical preview. All of the IDE extensions for OpenShift leverage &lt;code&gt;odo&lt;/code&gt;, bringing iterative development and deployment flows directly to developers.&lt;/p&gt; &lt;h3&gt;Helm&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/cli_reference/helm_cli/getting-started-with-helm-on-openshift-container-platform.html"&gt;Helm 3.2&lt;/a&gt; is a package manager for Kubernetes that helps developers create templated packages called &lt;em&gt;charts&lt;/em&gt; for installing and updating applications. The latest updates include displaying rich chart descriptions in the developer catalog and managing the Helm release lifecycle with features such as upgrade and rollback directly in the OpenShift console.&lt;/p&gt; &lt;h3&gt;oc new-app&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;oc new-app&lt;/code&gt; command now defaults to creating Kubernetes deployments, and can also create OpenShift &lt;code&gt;DeploymentConfigs&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;CI/CD&lt;/h2&gt; &lt;p&gt;OpenShift 4.5 offers a collection of CI/CD updates as well, from OpenShift Pipelines to Tekton Hub, Red Hat extensions for IDEs, and Argo CD.&lt;/p&gt; &lt;h3&gt;OpenShift Pipelines&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/pipelines/understanding-openshift-pipelines.html"&gt;OpenShift Pipelines 1.1&lt;/a&gt; automates and controls application delivery across on-premises and public cloud platforms with maintenance-free Kubernetes-native &lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;CI/CD pipelines&lt;/a&gt;. The latest update adds enhancements for Git webhooks, credentials management for private Git repositories, and image registries and insights into pipeline metrics in Prometheus.&lt;/p&gt; &lt;h3&gt;Tekton Hub&lt;/h3&gt; &lt;p&gt;Furthermore, &lt;a target="_blank" rel="nofollow" href="https://hub-preview.tekton.dev"&gt;Tekton Hub&lt;/a&gt; was launched within the Tekton community as a central hub for discovering and using Tekton resources in pipelines.&lt;/p&gt; &lt;h3&gt;Argo CD&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://argoproj.github.io/argo-cd/"&gt;Argo CD&lt;/a&gt; is a declarative continuous delivery tool for Kubernetes following the GitOps pattern of treating Git repositories as the source of truth for application and infrastructure configuration and deployments. Red Hat &lt;a href="https://www.redhat.com/en/about/press-releases/red-hat-and-intuit-join-forces-argo-project-extending-gitops-community-innovation-better-manage-multi-cluster-cloud-native-applications-scale"&gt;recently joined the Argo CD community&lt;/a&gt; as a member of the steering committee in order to bring Argo CD into the OpenShift portfolio of developer tools.&lt;/p&gt; &lt;h3&gt;Red Hat extensions for CI/CD systems&lt;/h3&gt; &lt;p&gt;Red Hat extensions for CI/CD systems allow teams to get the most out of OpenShift and Kubernetes while using the CI/CD tools that best fit their needs. We updated our Tekton extension for &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/publishers/redhat"&gt;VS Code&lt;/a&gt;. These CI/CD extensions allow developers to execute commands to OpenShift and Kubernetes for &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/items?itemName=redhat.openshift-vsts"&gt;Azure DevOps&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://github.com/marketplace/actions/openshift-action"&gt;GitHub Actions&lt;/a&gt;, &lt;a href="https://plugins.jenkins.io/ui/search?sort=relevance&amp;#38;categories=&amp;#38;labels=&amp;#38;view=Tiles&amp;#38;page=1&amp;#38;query=openshift"&gt;Jenkins&lt;/a&gt;, and Tekton. You also can run CI/CD jobs on the cluster using Tekton, Jenkins, and the newly announced option to &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/blog/installing-the-gitlab-runner-the-openshift-way"&gt;run GitLab runners on OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;IDEs and extensions&lt;/h2&gt; &lt;p&gt;OpenShift 4.5 also interacts with a number of IDE-related improvements.&lt;/p&gt; &lt;h3&gt;Red Hat CodeReady Workspaces&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/technologies/jboss-middleware/codeready-workspaces"&gt;Red Hat CodeReady Workspaces 2.2&lt;/a&gt; uses Kubernetes and containers to provide development or operations team members with a consistent, secure, and zero-configuration development environment. This release allows for faster workspace loading—and what developer doesn&amp;#8217;t love faster tools? Also, it is possible to support multiple devfile registries, which allows for additional language, framework, and runtime support from various sources. You can tune workspaces with appropriate Kubernetes requests and limits to optimize resource utilization and performance.&lt;/p&gt; &lt;h3&gt;Red Hat CodeReady Studio&lt;/h3&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/technologies/jboss-middleware/codeready-studio"&gt;Red Hat CodeReady Studio 12.16&lt;/a&gt; is an Eclipse-based IDE preconfigured to support Red Hat&amp;#8217;s application development components and tools. This update allows you to create secure URLs (routes) for your OpenShift application components. Other updates include new versions of Hibernate and Wildfly.&lt;/p&gt; &lt;h3&gt;Red Hat extensions for IDEs&lt;/h3&gt; &lt;p&gt;Red Hat extensions for IDEs are designed to let teams use the tools that they already have, but also take advantage of new technologies like OpenShift, Kubernetes, &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Kafka&lt;/a&gt;, Camel, Quarkus, Tekton, and many more. We&amp;#8217;ve updated our IDE extensions for the &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/publishers/redhat"&gt;VS Code&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://plugins.jetbrains.com/plugin/12030-openshift-connector-by-red-hat"&gt;JetBrains&lt;/a&gt; IDEs, including IntelliJ and Pycharm.&lt;/p&gt; &lt;h2&gt;Runtimes&lt;/h2&gt; &lt;p&gt;With the &lt;a href="https://www.redhat.com/en/about/press-releases/red-hat-advances-java-kubernetes-delivers-quarkus-fully-supported-runtime-cloud-native-development"&gt;recent addition of Quarkus&lt;/a&gt; as a supported runtime in Red Hat&amp;#8217;s application services portfolio, developers can use Quarkus with JVM optimizations that reduce startup time and memory consumption for new Java applications. Quarkus makes Java well-suited for cloud-native, &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/topics/event-driven/"&gt;event-driven application architectures&lt;/a&gt;. Further, it spurs innovation beyond the runtime with an &lt;a target="_blank" rel="nofollow" href="https://code.quarkus.io/"&gt;ecosystem of application extensions&lt;/a&gt; that configure, boot, and integrate a framework or technology into the Quarkus application.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: OpenShift 4.5 includes many more updates. Be sure to check out &lt;a href="https://developers.redhat.com/middleware"&gt;Red Hat Developer&amp;#8217;s Middleware and Application Services&lt;/a&gt; page for details.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;There is only so much that I can include in this report. With more time, I would add details about consuming application services via automated operations from the Red Hat Marketplace and community Kubernetes Operators via OperatorHub.io. I would also add details about specific updates for any of the &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/publishers/redhat"&gt;VS Code extensions&lt;/a&gt; in OpenShift 4.5.&lt;/p&gt; &lt;p&gt;We work hard to deliver tools and services that bring joy to many kinds of developers working across Kubernetes and OpenShift. One way we accomplish this is by getting feedback early and often. You can get involved by joining our hosted &lt;a target="_blank" rel="nofollow" href="https://groups.google.com/g/openshift-dev-users"&gt;feedback sessions&lt;/a&gt; or submitting feedback directly to any of the open source projects that interest you. You can also visit the &lt;a href="https://developers.redhat.com/topics/developer-tools"&gt;Red Hat developer tools portal&lt;/a&gt; to learn more and get started with the tools mentioned in this article.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fopenshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more%2F&amp;#38;linkname=OpenShift%204.5%3A%20Bringing%20developers%20joy%20with%20Kubernetes%201.18%20and%20so%20much%20more" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fopenshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more%2F&amp;#38;linkname=OpenShift%204.5%3A%20Bringing%20developers%20joy%20with%20Kubernetes%201.18%20and%20so%20much%20more" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fopenshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more%2F&amp;#38;linkname=OpenShift%204.5%3A%20Bringing%20developers%20joy%20with%20Kubernetes%201.18%20and%20so%20much%20more" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fopenshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more%2F&amp;#38;linkname=OpenShift%204.5%3A%20Bringing%20developers%20joy%20with%20Kubernetes%201.18%20and%20so%20much%20more" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fopenshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more%2F&amp;#38;linkname=OpenShift%204.5%3A%20Bringing%20developers%20joy%20with%20Kubernetes%201.18%20and%20so%20much%20more" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fopenshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more%2F&amp;#38;linkname=OpenShift%204.5%3A%20Bringing%20developers%20joy%20with%20Kubernetes%201.18%20and%20so%20much%20more" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fopenshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more%2F&amp;#38;linkname=OpenShift%204.5%3A%20Bringing%20developers%20joy%20with%20Kubernetes%201.18%20and%20so%20much%20more" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fopenshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more%2F&amp;#038;title=OpenShift%204.5%3A%20Bringing%20developers%20joy%20with%20Kubernetes%201.18%20and%20so%20much%20more" data-a2a-url="https://developers.redhat.com/blog/2020/08/18/openshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more/" data-a2a-title="OpenShift 4.5: Bringing developers joy with Kubernetes 1.18 and so much more"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/18/openshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more/"&gt;OpenShift 4.5: Bringing developers joy with Kubernetes 1.18 and so much more&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/NbSnXzu6mk8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Since the first Red Hat OpenShift release in 2015, Red Hat has put out numerous releases based on Kubernetes. Five years later, Kubernetes is celebrating its sixth birthday, and last month, we announced the general availability of Red Hat OpenShift Container Platform 4.5. In this article, I offer a high-level view of the latest OpenShift [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/18/openshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more/"&gt;OpenShift 4.5: Bringing developers joy with Kubernetes 1.18 and so much more&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/18/openshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">764757</post-id><dc:creator>Steve Speicher</dc:creator><dc:date>2020-08-18T07:00:21Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/18/openshift-4-5-bringing-developers-joy-with-kubernetes-1-18-and-so-much-more/</feedburner:origLink></entry><entry><title>iptables: The two variants and their relationship with nftables</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/wN0CyNJ6btk/" /><category term="Linux" /><category term="Open source" /><category term="Security" /><category term="iptables" /><category term="iptables vs nftables" /><category term="nftables" /><category term="RHEL" /><category term="rhel 8" /><author><name>Eric Garver</name></author><id>https://developers.redhat.com/blog/?p=740187</id><updated>2020-08-18T07:00:07Z</updated><published>2020-08-18T07:00:07Z</published><content type="html">&lt;p&gt;In &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) 8, the userspace utility program &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Iptables"&gt;&lt;code&gt;iptables&lt;/code&gt;&lt;/a&gt; has a close relationship to its successor, &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Nftables"&gt;&lt;code&gt;nftables&lt;/code&gt;&lt;/a&gt;. The association between the two utilities is subtle, which has led to confusion among Linux users and developers. In this article, I attempt to clarify the relationship between the two variants of &lt;code&gt;iptables&lt;/code&gt; and its successor program, &lt;code&gt;nftables&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;The kernel API&lt;/h2&gt; &lt;p&gt;In the beginning, there was only &lt;code&gt;iptables&lt;/code&gt;. It lived a good, long life in Linux history, but it wasn&amp;#8217;t without pain points. Later, &lt;code&gt;nftables&lt;/code&gt; appeared. It presented an opportunity to learn from the mistakes made with &lt;code&gt;iptables&lt;/code&gt; and improve on them.&lt;/p&gt; &lt;p&gt;The most important &lt;code&gt;nftables&lt;/code&gt; improvement, in the context of this article, is the kernel API. The kernel API is how user space programs the kernel. You can use either the &lt;code&gt;nft&lt;/code&gt; command or a variant of the &lt;code&gt;iptables&lt;/code&gt; command to access the kernel API. We&amp;#8217;ll focus on the &lt;code&gt;iptables&lt;/code&gt; variant.&lt;/p&gt; &lt;h2&gt;Two variants of the iptables command&lt;/h2&gt; &lt;p&gt;The two variants of the &lt;code&gt;iptables&lt;/code&gt; command are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;legacy&lt;/code&gt;: Often referred to as &lt;code&gt;iptables-legacy.&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;nf_tables&lt;/code&gt;: Often referred to as &lt;code&gt;iptables-nft&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The newer &lt;code&gt;iptables-nft&lt;/code&gt; command provides a bridge to the &lt;code&gt;nftables&lt;/code&gt; kernel API and infrastructure. You can find out which variant is in use by looking up the &lt;code&gt;iptables&lt;/code&gt; version. For &lt;code&gt;iptables-nft&lt;/code&gt;, the variant will be shown in parentheses after the version number, denoted as &lt;code&gt;nf_tables&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;root@rhel-8 # iptables -V iptables v1.8.4 (nf_tables) &lt;/pre&gt; &lt;p&gt;For &lt;code&gt;iptables-legacy&lt;/code&gt;, the variant will either be absent, or it will show &lt;code&gt;legacy&lt;/code&gt; in parentheses:&lt;/p&gt; &lt;pre&gt;root@rhel-7 # iptables -V iptables v1.4.21 &lt;/pre&gt; &lt;p&gt;You can also identify &lt;code&gt;iptables-nft&lt;/code&gt; by checking whether the &lt;code&gt;iptables&lt;/code&gt; binary is a symbolic link to &lt;code&gt;xtables-nft-multi&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;root@rhel-8 # ls -al /usr/sbin/iptables lrwxrwxrwx. 1 root root 17 Mar 17 10:22 /usr/sbin/iptables -&amp;#62; xtables-nft-multi &lt;/pre&gt; &lt;h2&gt;Using iptables-nft&lt;/h2&gt; &lt;p&gt;As I noted earlier, the &lt;code&gt;nftables&lt;/code&gt; utility improves the kernel API. The &lt;code&gt;iptables-nft&lt;/code&gt; command allows &lt;code&gt;iptables&lt;/code&gt; users to take advantage of the improvements. The &lt;code&gt;iptables-nft&lt;/code&gt; command uses the newer &lt;code&gt;nftables&lt;/code&gt; kernel API but reuses the &lt;code&gt;legacy&lt;/code&gt; packet-matching code. As a result, you get the following benefits while using the familiar &lt;code&gt;iptables&lt;/code&gt; command:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Atomic rules updates.&lt;/li&gt; &lt;li&gt;Per-network namespace locking.&lt;/li&gt; &lt;li&gt;No file-based locking (for example: /run/xtables.lock).&lt;/li&gt; &lt;li&gt;Fast updates to the incremental ruleset.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These benefits are mostly transparent to the user.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The userspace command for &lt;code&gt;nftables&lt;/code&gt; is &lt;code&gt;nft&lt;/code&gt;. It has its own syntax and grammar.&lt;/p&gt; &lt;h3&gt;Packet matching is the same&lt;/h3&gt; &lt;p&gt;It&amp;#8217;s important to understand that while there are two variants of &lt;code&gt;iptables&lt;/code&gt;, packet matching utilizes the &lt;em&gt;same&lt;/em&gt; code. Regardless of the variant that you are using, the same packet-matching features are available and behave identically. Another term for the packet matching code in the kernel is &lt;code&gt;xtables&lt;/code&gt;.  Both variants, &lt;code&gt;iptables-legacy&lt;/code&gt; and &lt;code&gt;iptables-nft&lt;/code&gt;, use the same &lt;code&gt;xtables&lt;/code&gt; code. This diagram provides a visual aid. I included &lt;code&gt;nft&lt;/code&gt; for completeness:&lt;/p&gt; &lt;pre&gt;+--------------+ +--------------+ +--------------+ | iptables | | iptables | | nft | USER | legacy | | nft | | (nftables) | SPACE +--------------+ +--------------+ +--------------+ | | | ====== | ===== KERNEL API ======= | ======= | ===================== | | | +--------------+ +--------------+ | iptables | | nftables | KERNEL | API | | API | SPACE +--------------+ +--------------+ | | | | | | +--------------+ | | +--------------+ | xtables |--------+ +-----| nftables | | match | | match | +--------------+ +--------------+ &lt;/pre&gt; &lt;h2&gt;The iptables rules appear in the nftables rule listing&lt;/h2&gt; &lt;p&gt;An interesting consequence of &lt;code&gt;iptables-nft&lt;/code&gt; using &lt;code&gt;nftables&lt;/code&gt; infrastructure is that the &lt;code&gt;iptables&lt;/code&gt; ruleset appears in the &lt;code&gt;nftables&lt;/code&gt; rule listing. Let&amp;#8217;s consider an example based on a simple rule:&lt;/p&gt; &lt;pre&gt;root@rhel-8 # iptables -A INPUT -s 10.10.10.0/24 -j ACCEPT &lt;/pre&gt; &lt;p&gt;Showing this rule through the &lt;code&gt;iptables&lt;/code&gt; command yields what we might expect:&lt;/p&gt; &lt;pre&gt;root@rhel-8 # iptables -nL INPUT Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT all -- 10.10.10.0/24 0.0.0.0/0 &lt;/pre&gt; &lt;p&gt;But it will also be shown in the &lt;code&gt;nft&lt;/code&gt; ruleset:&lt;/p&gt; &lt;pre&gt;root@rhel-8 # nft list ruleset table ip filter { chain INPUT { type filter hook input priority filter; policy accept; ip saddr 10.10.10.0/24 counter packets 0 bytes 0 accept } } &lt;/pre&gt; &lt;p&gt;Note how the &lt;code&gt;iptables&lt;/code&gt; rule was automatically translated into the &lt;code&gt;nft&lt;/code&gt; syntax. Studying the automatic translation is one way to discover the &lt;code&gt;nft&lt;/code&gt; equivalents of the &lt;code&gt;iptables&lt;/code&gt; rules. In some cases, however, there isn&amp;#8217;t a direct equivalent. In those cases, &lt;code&gt;nft&lt;/code&gt; will let you know by showing a comment like this one:&lt;/p&gt; &lt;pre&gt;table ip nat { chain PREROUTING { meta l4proto tcp counter packets 0 bytes 0 # xt_REDIRECT } } &lt;/pre&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;To summarize, the &lt;code&gt;iptables-nft&lt;/code&gt; variant utilizes the newer &lt;code&gt;nftables&lt;/code&gt; kernel infrastructure. This gives the variant some benefits over &lt;code&gt;iptables-legacy&lt;/code&gt; while allowing it to remain a 100% compatible drop-in replacement for the legacy command. Note, however, that &lt;code&gt;iptables-nft&lt;/code&gt; and &lt;code&gt;nftables&lt;/code&gt; are &lt;em&gt;not&lt;/em&gt; equivalent. They merely share infrastructure.&lt;/p&gt; &lt;p&gt;It is also important to note that while &lt;code&gt;iptables-nft&lt;/code&gt; can supplant &lt;code&gt;iptables-legacy&lt;/code&gt;, you should never use them simultaneously.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fiptables-the-two-variants-and-their-relationship-with-nftables%2F&amp;#38;linkname=iptables%3A%20The%20two%20variants%20and%20their%20relationship%20with%20nftables" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fiptables-the-two-variants-and-their-relationship-with-nftables%2F&amp;#38;linkname=iptables%3A%20The%20two%20variants%20and%20their%20relationship%20with%20nftables" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fiptables-the-two-variants-and-their-relationship-with-nftables%2F&amp;#38;linkname=iptables%3A%20The%20two%20variants%20and%20their%20relationship%20with%20nftables" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fiptables-the-two-variants-and-their-relationship-with-nftables%2F&amp;#38;linkname=iptables%3A%20The%20two%20variants%20and%20their%20relationship%20with%20nftables" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fiptables-the-two-variants-and-their-relationship-with-nftables%2F&amp;#38;linkname=iptables%3A%20The%20two%20variants%20and%20their%20relationship%20with%20nftables" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fiptables-the-two-variants-and-their-relationship-with-nftables%2F&amp;#38;linkname=iptables%3A%20The%20two%20variants%20and%20their%20relationship%20with%20nftables" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fiptables-the-two-variants-and-their-relationship-with-nftables%2F&amp;#38;linkname=iptables%3A%20The%20two%20variants%20and%20their%20relationship%20with%20nftables" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F18%2Fiptables-the-two-variants-and-their-relationship-with-nftables%2F&amp;#038;title=iptables%3A%20The%20two%20variants%20and%20their%20relationship%20with%20nftables" data-a2a-url="https://developers.redhat.com/blog/2020/08/18/iptables-the-two-variants-and-their-relationship-with-nftables/" data-a2a-title="iptables: The two variants and their relationship with nftables"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/18/iptables-the-two-variants-and-their-relationship-with-nftables/"&gt;iptables: The two variants and their relationship with nftables&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/wN0CyNJ6btk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In Red Hat Enterprise Linux (RHEL) 8, the userspace utility program iptables has a close relationship to its successor, nftables. The association between the two utilities is subtle, which has led to confusion among Linux users and developers. In this article, I attempt to clarify the relationship between the two variants of iptables and its [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/18/iptables-the-two-variants-and-their-relationship-with-nftables/"&gt;iptables: The two variants and their relationship with nftables&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/18/iptables-the-two-variants-and-their-relationship-with-nftables/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">740187</post-id><dc:creator>Eric Garver</dc:creator><dc:date>2020-08-18T07:00:07Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/18/iptables-the-two-variants-and-their-relationship-with-nftables/</feedburner:origLink></entry><entry><title>OpenShift joins the Argo CD community (KubeCon Europe 2020)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/8Zt---AGpPQ/" /><category term="CI/CD" /><category term="DevOps" /><category term="Kubernetes" /><category term="Operator" /><category term="Argo CD" /><category term="configuration drift" /><category term="gitops" /><category term="kubecon" /><category term="kubecon 2020" /><category term="Kubernetes CI/CD" /><category term="openshift" /><author><name>Siamak Sadeghianfar</name></author><id>https://developers.redhat.com/blog/?p=764667</id><updated>2020-08-17T07:00:08Z</updated><published>2020-08-17T07:00:08Z</published><content type="html">&lt;p&gt;As &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; platform adoption grow and organizations move a larger portion of their infrastructure to these platforms, organizations are increasingly faced with the challenge of managing hybrid multicluster environments across the public cloud and on-premises infrastructure. While this approach brings flexibility and scalability to managing applications, the ability to ensure configuration consistency across these clusters, and the ability to roll out applications to multiple clusters in a consistent manner becomes a necessity. Enter the &lt;a target="_blank" rel="nofollow" href="https://argoproj.github.io/argo-cd/"&gt;Argo CD&lt;/a&gt; GitOps Kubernetes Operator.&lt;/p&gt; &lt;h2&gt;GitOps, Kubernetes, and configuration consistency&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://about.gitlab.com/blog/2020/04/17/why-gitops-should-be-workflow-of-choice/"&gt;GitOps&lt;/a&gt; is an increasingly popular set of practices for managing the complexities of running hybrid &lt;a href="https://developers.redhat.com/courses/foundations"&gt;multicluster Kubernetes&lt;/a&gt; infrastructure. GitOps centers on treating Git repositories as the single source of truth and applying Git workflows that have been consistently used for application development to infrastructure and application operators.&lt;/p&gt; &lt;p&gt;Declarative configuration and &lt;a href="https://developers.redhat.com/devnation/tech-talks/gitops"&gt;GitOps&lt;/a&gt; principles are the core of the &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;OpenShift Container Platform&lt;/a&gt; values that led us to make OpenShift one of the most declarative Kubernetes platforms in the world. Virtually all aspects of OpenShift can be configured declaratively, taking advantage of Kubernetes custom resources that allow GitOps practitioners to store OpenShift configuration resources in a Git repo. This makes sure that all OpenShift cluster configurations are in sync with the source of truth in Git using the &lt;a href="https://www.openshift.com/blog/introduction-to-gitops-with-openshift" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;practitioners&amp;#8217; tools of choice&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Argo CD and OpenShift&lt;/h2&gt; &lt;p&gt;Argo CD is a popular Cloud Native Computing Foundation (CNCF) open source GitOps &lt;a href="https://developers.redhat.com/topics/kubernetes/operators/"&gt;Kubernetes Operator&lt;/a&gt; for declarative configuration on Kubernetes clusters. Argo CD has a lively community of users with a growing user base among OpenShift customers. It is in fact one of the most popular &lt;a href="https://operatorhub.io" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;community Kubernetes Operators&lt;/a&gt; on the OpenShift platform.&lt;/p&gt; &lt;p&gt;Red Hat has a long history of engaging with community projects that address enterprise needs. Continuing on that journey, we are now collaborating with Intuit and joining the Argo community as a member of the bootstrap steering committee. Doing this lets us actively contribute to the Argo community and help OpenShift customers take advantage of Argo CD for managing their applications in multicluster OpenShift and Kubernetes infrastructure using GitOps principles.&lt;/p&gt; &lt;p&gt;Argo CD, shown in Figure 1, works based on the GitOps pattern of using Git repositories as the source of truth for defining the desired application state. Kubernetes manifests can be specified in several ways, such as &lt;a href="https://developers.redhat.com/blog/2020/07/20/advanced-helm-support-in-the-openshift-4-5-web-console/"&gt;Helm&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://github.com/kubernetes-sigs/kustomize"&gt;kustomize&lt;/a&gt;, and plain JSON or YAML, among others. Argo CD automates deploying applications to multiple customers by syncing Kubernetes manifests to the target clusters and making sure the clusters are in the desired state. Furthermore, it monitors the state of the deployed applications on Kubernetes clusters and constantly compares them to the manifests stored in Git, in order to detect any drift from the desired state; for example, in case of manual changes. When drift is detected, admins can be notified, or Argo CD can be configured to automatically correct the state of the application on the cluster based on the Git repositories.&lt;/p&gt; &lt;div id="attachment_766217" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-766217" class="wp-image-766217 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Argo-CD-application-state-1024x575.png" alt="ArgoCD application state chart showing that the application is fully synced." width="640" height="359" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Argo-CD-application-state-1024x575.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Argo-CD-application-state-300x169.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Argo-CD-application-state-768x432.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-766217" class="wp-caption-text"&gt;Figure 1: Viewing application state in Argo CD.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Adi Sakala, senior director for OpenShift and developer engineering at Red Hat, states:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;&lt;em&gt;&amp;#8220;OpenShift continues to help organizations through the Cloud Native journey modernizing their data centers and development teams. Continuous deployment and delivery of infra &amp;#38; applications plays a critical role as organizations rethink and retool delivery processes to scale the adoption of containerized development. &lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;&amp;#8220;The Argo project has widely been recognized and adopted in the Kubernetes ecosystem providing continuous delivery tooling. Red Hat as a leader of open source and hybrid cloud platform is happy to join hands with Intuit and the rest of the Argo community to further help drive the project. We believe when communities thrive with open governance and vibrant users it sets up for sustained growth of the project. Having Argo as a choice for OpenShift users will empower and enable enterprises to declaratively build and run cloud native applications on OpenShift using GitOps. We are thrilled to give OpenShift users this option.&amp;#8221;&lt;br /&gt; &lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt; &lt;h2&gt;What’s next&lt;/h2&gt; &lt;p&gt;Argo CD is available today as an Argo community-owned Kubernetes Operator on the OperatorHub accessible through the OpenShift console admin perspective. In the coming months as we ramp up our engagement and contributions upstream in the Argo community, we will simultaneously drive a tighter integration within the OpenShift portfolio of developer tools that span over the three distinct phases that a change goes through until it reaches production (see Figure 2):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Local development&lt;/strong&gt; on the developer’s workstation with &lt;a href="https://developers.redhat.com/products/odo/overview"&gt;&lt;code&gt;odo&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;CodeReady Containers&lt;/a&gt;, or in a web-based workspace with &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;CodeReady Workspaces&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;&lt;strong&gt;Continuous integration (CI)&lt;/strong&gt;&lt;/a&gt; with &lt;a href="https://developers.redhat.com/blog/2020/04/30/creating-pipelines-with-openshift-4-4s-new-pipeline-builder-and-tekton-pipelines/"&gt;Tekton Pipelines&lt;/a&gt; to build and test applications on every Git change.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Continuous delivery (CD)&lt;/strong&gt; with Argo CD to deliver applications to multicluster staging and production clusters.&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_764677" style="width: 621px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-764677" class="wp-image-764677 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/image1.png" alt="the cycle from local development iterations to continue integration and continuous delivery" width="611" height="162" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/image1.png 611w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/image1-300x80.png 300w" sizes="(max-width: 611px) 100vw, 611px" /&gt;&lt;p id="caption-attachment-764677" class="wp-caption-text"&gt;Figure 2: The three phases a change goes through in a CI/CD pipeline.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We are excited about the road ahead with the addition of Argo CD to the OpenShift developer tools portfolio. Stay tuned for more exciting news over the coming months on what this means for application development workflows on OpenShift.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F17%2Fopenshift-joins-the-argo-cd-community-kubecon-europe-2020%2F&amp;#38;linkname=OpenShift%20joins%20the%20Argo%20CD%20community%20%28KubeCon%20Europe%202020%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F17%2Fopenshift-joins-the-argo-cd-community-kubecon-europe-2020%2F&amp;#38;linkname=OpenShift%20joins%20the%20Argo%20CD%20community%20%28KubeCon%20Europe%202020%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F17%2Fopenshift-joins-the-argo-cd-community-kubecon-europe-2020%2F&amp;#38;linkname=OpenShift%20joins%20the%20Argo%20CD%20community%20%28KubeCon%20Europe%202020%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F17%2Fopenshift-joins-the-argo-cd-community-kubecon-europe-2020%2F&amp;#38;linkname=OpenShift%20joins%20the%20Argo%20CD%20community%20%28KubeCon%20Europe%202020%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F17%2Fopenshift-joins-the-argo-cd-community-kubecon-europe-2020%2F&amp;#38;linkname=OpenShift%20joins%20the%20Argo%20CD%20community%20%28KubeCon%20Europe%202020%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F17%2Fopenshift-joins-the-argo-cd-community-kubecon-europe-2020%2F&amp;#38;linkname=OpenShift%20joins%20the%20Argo%20CD%20community%20%28KubeCon%20Europe%202020%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F17%2Fopenshift-joins-the-argo-cd-community-kubecon-europe-2020%2F&amp;#38;linkname=OpenShift%20joins%20the%20Argo%20CD%20community%20%28KubeCon%20Europe%202020%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F17%2Fopenshift-joins-the-argo-cd-community-kubecon-europe-2020%2F&amp;#038;title=OpenShift%20joins%20the%20Argo%20CD%20community%20%28KubeCon%20Europe%202020%29" data-a2a-url="https://developers.redhat.com/blog/2020/08/17/openshift-joins-the-argo-cd-community-kubecon-europe-2020/" data-a2a-title="OpenShift joins the Argo CD community (KubeCon Europe 2020)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/17/openshift-joins-the-argo-cd-community-kubecon-europe-2020/"&gt;OpenShift joins the Argo CD community (KubeCon Europe 2020)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/8Zt---AGpPQ" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;As Kubernetes and Red Hat OpenShift platform adoption grow and organizations move a larger portion of their infrastructure to these platforms, organizations are increasingly faced with the challenge of managing hybrid multicluster environments across the public cloud and on-premises infrastructure. While this approach brings flexibility and scalability to managing applications, the ability to ensure configuration [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/17/openshift-joins-the-argo-cd-community-kubecon-europe-2020/"&gt;OpenShift joins the Argo CD community (KubeCon Europe 2020)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/17/openshift-joins-the-argo-cd-community-kubecon-europe-2020/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">764667</post-id><dc:creator>Siamak Sadeghianfar</dc:creator><dc:date>2020-08-17T07:00:08Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/17/openshift-joins-the-argo-cd-community-kubecon-europe-2020/</feedburner:origLink></entry><entry><title>Introduction to cloud-native CI/CD with Tekton (KubeCon Europe 2020)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/eif-onQuBG4/" /><category term="CI/CD" /><category term="DevOps" /><category term="Kubernetes" /><category term="VS Code" /><category term="ci/cd pipeline" /><category term="kubecon" /><category term="kubecon 2020" /><category term="openshift" /><category term="Tekton" /><category term="tekton pipelines" /><author><name>Jan Kleinert</name></author><id>https://developers.redhat.com/blog/?p=764557</id><updated>2020-08-14T07:00:52Z</updated><published>2020-08-14T07:00:52Z</published><content type="html">&lt;p&gt;If you’re interested in cloud-native &lt;a href="https://developers.redhat.com/topics/ci-cd/"&gt;CI/CD and Tekton&lt;/a&gt; but haven’t had a chance to get hands-on with the technology yet, the &lt;a target="_blank" rel="nofollow" href="https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/"&gt;KubeCon Europe Virtual&lt;/a&gt; event provides an opportunity to do that. Tekton is a powerful and flexible open source framework for creating cloud-native CI/CD pipelines. It integrates with &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; and allows developers to build, test, and deploy across multiple cloud providers and on-premises clusters as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_764567" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Screen-Shot-2020-08-11-at-12.30.32-PM.png"&gt;&lt;img aria-describedby="caption-attachment-764567" class="wp-image-764567" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Screen-Shot-2020-08-11-at-12.30.32-PM.png" alt="Diagram showing a cloud-native CI/CD pipeline with Tekton and Kubernetes" width="640" height="213" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Screen-Shot-2020-08-11-at-12.30.32-PM.png 671w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Screen-Shot-2020-08-11-at-12.30.32-PM-300x100.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-764567" class="wp-caption-text"&gt;Figure 1: A cloud-native CI/CD pipeline with Tekton and Kubernetes.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;On Monday, 17 August 2020, from 16:55 &amp;#8211; 18:15 CEST, Jan Kleinert and Joel Lord will lead a &lt;a target="_blank" rel="nofollow" href="https://kccnceu20.sched.com/event/62008bbe06430e9c0c991ca8f9e6b8b9"&gt;hands-on tutorial&lt;/a&gt; focused on cloud-native CI/CD with Tekton. This tutorial will begin with an introduction to cloud-native CI/CD and the fundamental concepts and benefits of Tekton. After that introduction, you&amp;#8217;ll participate in hands-on exercises to practice with Tekton steps, tasks, resources, and pipelines through both “Hello World” and more realistic examples. You will also get an introduction on how to use the &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-tekton-pipelines"&gt;Tekton Pipelines VS Code extension&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Start learning more about &lt;a href="https://developers.redhat.com/blog/2020/04/30/creating-pipelines-with-openshift-4-4s-new-pipeline-builder-and-tekton-pipelines"&gt;CI/CD and Tekton&lt;/a&gt; today, and &lt;a target="_blank" rel="nofollow" href="https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/"&gt;register for KubeCon Europe 2020 Virtual&lt;/a&gt; to attend the tutorial. This is just one of the many sessions presented by Red Hatters at KubeCon Europe. You can find &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/events/webinar/red-hat-kubecon-europe-2020?sc_cid=7013a000002gqPrAAI#overview"&gt;the full list here&lt;/a&gt;, along with information about the Red Hat booth, demo theatre, the Open Source Arcade, and more.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F14%2Fintroduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020%2F&amp;#38;linkname=Introduction%20to%20cloud-native%20CI%2FCD%20with%20Tekton%20%28KubeCon%20Europe%202020%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F14%2Fintroduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020%2F&amp;#38;linkname=Introduction%20to%20cloud-native%20CI%2FCD%20with%20Tekton%20%28KubeCon%20Europe%202020%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F14%2Fintroduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020%2F&amp;#38;linkname=Introduction%20to%20cloud-native%20CI%2FCD%20with%20Tekton%20%28KubeCon%20Europe%202020%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F14%2Fintroduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020%2F&amp;#38;linkname=Introduction%20to%20cloud-native%20CI%2FCD%20with%20Tekton%20%28KubeCon%20Europe%202020%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F14%2Fintroduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020%2F&amp;#38;linkname=Introduction%20to%20cloud-native%20CI%2FCD%20with%20Tekton%20%28KubeCon%20Europe%202020%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F14%2Fintroduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020%2F&amp;#38;linkname=Introduction%20to%20cloud-native%20CI%2FCD%20with%20Tekton%20%28KubeCon%20Europe%202020%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F14%2Fintroduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020%2F&amp;#38;linkname=Introduction%20to%20cloud-native%20CI%2FCD%20with%20Tekton%20%28KubeCon%20Europe%202020%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F14%2Fintroduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020%2F&amp;#038;title=Introduction%20to%20cloud-native%20CI%2FCD%20with%20Tekton%20%28KubeCon%20Europe%202020%29" data-a2a-url="https://developers.redhat.com/blog/2020/08/14/introduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020/" data-a2a-title="Introduction to cloud-native CI/CD with Tekton (KubeCon Europe 2020)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/14/introduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020/"&gt;Introduction to cloud-native CI/CD with Tekton (KubeCon Europe 2020)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/eif-onQuBG4" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;If you’re interested in cloud-native CI/CD and Tekton but haven’t had a chance to get hands-on with the technology yet, the KubeCon Europe Virtual event provides an opportunity to do that. Tekton is a powerful and flexible open source framework for creating cloud-native CI/CD pipelines. It integrates with Kubernetes and allows developers to build, test, and deploy [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/14/introduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020/"&gt;Introduction to cloud-native CI/CD with Tekton (KubeCon Europe 2020)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/14/introduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">764557</post-id><dc:creator>Jan Kleinert</dc:creator><dc:date>2020-08-14T07:00:52Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/14/introduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020/</feedburner:origLink></entry></feed>
